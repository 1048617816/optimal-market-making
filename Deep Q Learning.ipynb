{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QzeQrzMu1EPM"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "# make the simulation into an RL environment:\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from runstats import *\n",
    "import runstats\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2M5Wrp30Si_",
    "outputId": "e581e98b-3352-435a-9036-4b14a1de1ba4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/anaconda3/envs/GPU/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# MS: Using a discrete action space similar to the Market Making via Reinforcement Learning paper (https://arxiv.org/pdf/1804.04216.pdf, Section 3 - p.3)\n",
    "actions_num = 21   #MS: So the range of possibilities goes from 0.3% to 3% from TOB\n",
    "max_abs_dif = 4\n",
    "max_abs_spread = 20\n",
    "\n",
    "\n",
    "s0 = 100\n",
    "T = 1. # Total time.\n",
    "sigma = 2.  # Standard deviation.\n",
    "dt = .005  # Time step.\n",
    "beta = 0.5\n",
    "kappa = beta * 2\n",
    "k = 1.5\n",
    "A = 137.45\n",
    "\n",
    "def spread(beta, sigma, T_t, k):\n",
    "    return beta*sigma**2*(T_t) + 2/beta*np.log(1+beta/k)\n",
    "\n",
    "def r(beta, sigma, T_t, s, q):\n",
    "    return s - q*beta*sigma**2*(T_t)\n",
    "\n",
    "def l(A, k, d):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "      A : float\n",
    "        in Avellaneda A = \\lambda/\\alpha, where alpha is as above,\n",
    "        and lambda is the constant frequency of market buy and sell orders.\n",
    "      k : float\n",
    "        in Avellaneda k = alpha*K, where alpha ~ 1.5, \n",
    "        and K is such that \\delta p ~ Kln(Q) for a market order of size Q\n",
    "      d : float\n",
    "        in Avellaneda, d=distance to the mid price\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    \n",
    "      l : float:\n",
    "        in Avellaneda, l = lambda = Poisson intensity at which our agentâ€™s orders are\n",
    "        executed.\n",
    "    '''\n",
    "    return A*np.exp(-k*d) \n",
    "    #JK: eq. (12)    \n",
    "\n",
    "\n",
    "class AvellanedaEnv:\n",
    "    def __init__(self, s0, T, dt, sigma, beta, k, A, kappa, seed=0, is_discrete=True):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        s : float\n",
    "            Initial value of future/stock price.\n",
    "        b : float\n",
    "            Initial value of 'brecha'.\n",
    "        T : float\n",
    "            Total time.\n",
    "        dt : float\n",
    "            Time subdivision.\n",
    "        sigma : float\n",
    "            price volatility.\n",
    "        gamma : float\n",
    "            discount factor.\n",
    "        k : float\n",
    "            in Avellaneda k = alpha*K, where alpha ~ 1.5, \n",
    "            and K is such that \\delta p ~ Kln(Q) for a market order of size Q\n",
    "        A : float\n",
    "            in Avellaneda A = \\lambda/\\alpha, where alpha is as above,\n",
    "            and lambda is the constant frequency of market buy and sell orders.\n",
    "    \n",
    "        '''\n",
    "        self.s0 = s0\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.sigma = sigma\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        self.A = A\n",
    "        self.sqrtdt = np.sqrt(dt)\n",
    "        self.kappa = kappa\n",
    "        self.is_discrete = is_discrete\n",
    "        self.stats = runstats.ExponentialStatistics(decay=0.999)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # observation space: s (price), q, T-t (time remaining)\n",
    "        self.observation_space = gym.spaces.Box(low=np.array([0.0, -math.inf, 0.0]),\n",
    "                                     high=np.array([math.inf, math.inf,T]),\n",
    "                                     dtype=np.float32)\n",
    "        # action space: spread, ds\n",
    "        self.action_space = gym.spaces.Discrete(actions_num)\n",
    "        self.reward_range = (-math.inf,math.inf)\n",
    "        \n",
    "        self.metadata = None # useless field\n",
    "        \n",
    "    def reset(self,seed=0):\n",
    "        self.s = self.s0\n",
    "        self.q = 0.0\n",
    "        self.t = 0.0\n",
    "        self.w = 0.0\n",
    "        self.n = int(T/dt)\n",
    "        self.c_ = 0.0\n",
    "        return np.array((self.s,self.q,self.T))\n",
    "        \n",
    "    def step(self, action):\n",
    "        if self.is_discrete:\n",
    "            despl = (action-(actions_num-1)/2)*max_abs_dif/(actions_num-1)\n",
    "        else:\n",
    "            despl = action\n",
    "        ba_spread = spread(self.beta,self.sigma,self.T-self.t,self.k)\n",
    "\n",
    "        bid = self.s - despl - ba_spread/2\n",
    "        ask = self.s - despl + ba_spread/2\n",
    "                \n",
    "        db = self.s - bid\n",
    "        da = ask - self.s\n",
    "        \n",
    "        lb = l(A, k, db)\n",
    "        la = l(A, k, da)\n",
    "        \n",
    "        dnb = 1 if np.random.uniform() <= lb * self.dt else 0\n",
    "        dna = 1 if np.random.uniform() <= la * self.dt else 0\n",
    "        self.q += dnb - dna\n",
    "\n",
    "        self.c_ += -dnb * bid + dna * ask # cash\n",
    "\n",
    "        self.s += self.sigma * self.sqrtdt *(1 if np.random.uniform() < 0.5 else -1)\n",
    "\n",
    "        previous_w = self.w\n",
    "        self.w = self.c_ + self.q * self.s\n",
    "                \n",
    "        dw = (self.w - previous_w)\n",
    "        self.stats.push(dw)\n",
    "        #reward =  np.exp(-self.gamma*previous_w) - np.exp(-self.gamma*self.w) - 1/(self.n)\n",
    "        \n",
    "        #if self.t >= self.T:\n",
    "        reward = dw - self.kappa/2 * (dw - self.stats.mean())**2\n",
    "        \n",
    "        #if self.t >= self.T - self.dt:\n",
    "            #print(\"sum of dw: \" + str(sum(self.ws)))\n",
    "            #print(\"sum of kappa/2 * (dw - mu)**2: \" + str(sum(self.rews)))\n",
    "        \n",
    "        self.t += self.dt\n",
    "\n",
    "            \n",
    "        return np.array((self.s,self.q,self.T-self.t)), reward, self.t >= self.T, {'w':self.w}\n",
    "    \n",
    "env = AvellanedaEnv(s0, T, dt, sigma, beta, k, A,kappa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 480899), started 0:10:16 ago. (Use '!kill 480899' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8e027dcb7336fd36\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8e027dcb7336fd36\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "ohfqOsj10psv",
    "outputId": "650c7370-1b20-42d5-c23f-4fb073ae6e12",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found! Starting training...\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/DQN_2\n",
      "Eval num_timesteps=500, episode_reward=-7735.71 +/- 786.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.74e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.957     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 620       |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total timesteps  | 900       |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=-6760.36 +/- 990.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1500, episode_reward=-7234.79 +/- 681.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.23e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.91      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 818       |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total timesteps  | 1900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-6836.71 +/- 927.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=2500, episode_reward=-6768.97 +/- 696.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.77e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.862     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 889       |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total timesteps  | 2900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-6554.81 +/- 751.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=3500, episode_reward=-7680.69 +/- 635.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.68e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.815     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 932       |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total timesteps  | 3900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-7597.77 +/- 896.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=-7328.34 +/- 837.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.33e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.767     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 978       |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total timesteps  | 4900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-7395.17 +/- 519.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=5500, episode_reward=-7412.73 +/- 1574.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.41e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.72      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 1004      |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total timesteps  | 5900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-6959.03 +/- 696.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=6500, episode_reward=-7230.98 +/- 462.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.23e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.672     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 1031      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total timesteps  | 6900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-7096.95 +/- 336.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=7500, episode_reward=-7351.91 +/- 755.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.35e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.625     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 1052      |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total timesteps  | 7900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-7067.78 +/- 1021.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=8500, episode_reward=-7412.48 +/- 1098.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.41e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.577     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 1063      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total timesteps  | 8900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-7500.15 +/- 848.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=9500, episode_reward=-7052.93 +/- 731.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.05e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.53      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 1077      |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total timesteps  | 9900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-6935.96 +/- 639.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=10500, episode_reward=-7037.41 +/- 711.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.04e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.482     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 1089      |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total timesteps  | 10900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=-6761.86 +/- 692.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=11500, episode_reward=-6332.56 +/- 419.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.33e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.435     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 1098      |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total timesteps  | 11900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-7044.29 +/- 711.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=12500, episode_reward=-7458.83 +/- 831.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.46e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.387     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 1101      |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total timesteps  | 12900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=-6925.99 +/- 717.94\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=13500, episode_reward=-7236.10 +/- 828.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.24e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.34      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 1108      |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total timesteps  | 13900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=-7185.32 +/- 1033.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=14500, episode_reward=-7068.00 +/- 799.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.07e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.292     |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 1114      |\n",
      "|    time_elapsed     | 13        |\n",
      "|    total timesteps  | 14900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-7001.23 +/- 624.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=15500, episode_reward=-7190.49 +/- 1026.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.19e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.245     |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 1120      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total timesteps  | 15900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-6764.86 +/- 764.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=16500, episode_reward=-6947.46 +/- 1153.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.95e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.197     |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 1123      |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total timesteps  | 16900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=-6605.65 +/- 620.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=17500, episode_reward=-7605.81 +/- 831.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.61e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.15      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 1122      |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total timesteps  | 17900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=-6791.56 +/- 886.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=18500, episode_reward=-6337.65 +/- 518.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.34e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.102     |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 1125      |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total timesteps  | 18900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=-6817.56 +/- 1113.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=19500, episode_reward=-7458.66 +/- 526.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.46e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.0547    |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 1125      |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total timesteps  | 19900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-6803.42 +/- 611.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=20500, episode_reward=-6386.84 +/- 849.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.39e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 1125      |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total timesteps  | 20900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=-6831.97 +/- 627.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=21500, episode_reward=-6743.34 +/- 912.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.74e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 1123      |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total timesteps  | 21900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=-7068.92 +/- 200.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=22500, episode_reward=-6477.27 +/- 856.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 1126      |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total timesteps  | 22900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=-7591.47 +/- 777.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=23500, episode_reward=-7488.93 +/- 975.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.49e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 1129      |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total timesteps  | 23900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-6801.41 +/- 376.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=24500, episode_reward=-7014.88 +/- 881.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.01e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 1133      |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total timesteps  | 24900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-6161.99 +/- 763.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=25500, episode_reward=-6905.64 +/- 796.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.91e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 1133      |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total timesteps  | 25900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=-6700.34 +/- 396.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=26500, episode_reward=-7042.89 +/- 629.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.04e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 1134      |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total timesteps  | 26900     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=27000, episode_reward=-7606.62 +/- 1084.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=27500, episode_reward=-7562.77 +/- 627.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.56e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 1132      |\n",
      "|    time_elapsed     | 24        |\n",
      "|    total timesteps  | 27900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=-7257.33 +/- 666.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=28500, episode_reward=-6867.85 +/- 851.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.87e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 1135      |\n",
      "|    time_elapsed     | 25        |\n",
      "|    total timesteps  | 28900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=-7284.33 +/- 880.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=29500, episode_reward=-6803.65 +/- 920.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -6.8e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1136     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total timesteps  | 29900    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-6658.68 +/- 1133.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=30500, episode_reward=-7203.27 +/- 572.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -7.2e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 1137     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total timesteps  | 30900    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=-7660.81 +/- 685.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=31500, episode_reward=-7285.44 +/- 592.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.29e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 128       |\n",
      "|    fps              | 1140      |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total timesteps  | 31900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=-7058.06 +/- 353.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=32500, episode_reward=-6745.71 +/- 658.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.75e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 132       |\n",
      "|    fps              | 1143      |\n",
      "|    time_elapsed     | 28        |\n",
      "|    total timesteps  | 32900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=33000, episode_reward=-7893.38 +/- 1017.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=33500, episode_reward=-6967.06 +/- 908.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.97e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 136       |\n",
      "|    fps              | 1144      |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total timesteps  | 33900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=-6943.80 +/- 449.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=34500, episode_reward=-6824.78 +/- 787.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.82e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 140       |\n",
      "|    fps              | 1144      |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total timesteps  | 34900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-6958.50 +/- 771.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=35500, episode_reward=-7074.70 +/- 475.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.07e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 144       |\n",
      "|    fps              | 1141      |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total timesteps  | 35900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=-6893.48 +/- 882.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=36500, episode_reward=-6858.25 +/- 583.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.86e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 148       |\n",
      "|    fps              | 1140      |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total timesteps  | 36900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=-7615.78 +/- 363.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=37500, episode_reward=-7060.70 +/- 811.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.06e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 152       |\n",
      "|    fps              | 1139      |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total timesteps  | 37900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=-6486.77 +/- 803.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=38500, episode_reward=-6998.26 +/- 355.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -7e+03   |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 1141     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total timesteps  | 38900    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=-7712.90 +/- 548.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=39500, episode_reward=-7089.28 +/- 928.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.09e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 160       |\n",
      "|    fps              | 1141      |\n",
      "|    time_elapsed     | 34        |\n",
      "|    total timesteps  | 39900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-7494.01 +/- 808.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=40500, episode_reward=-7194.17 +/- 973.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.19e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 164       |\n",
      "|    fps              | 1142      |\n",
      "|    time_elapsed     | 35        |\n",
      "|    total timesteps  | 40900     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=41000, episode_reward=-6777.13 +/- 406.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=41500, episode_reward=-7126.24 +/- 680.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.13e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 168       |\n",
      "|    fps              | 1144      |\n",
      "|    time_elapsed     | 36        |\n",
      "|    total timesteps  | 41900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=-6903.62 +/- 469.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=42500, episode_reward=-6807.04 +/- 883.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.81e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 172       |\n",
      "|    fps              | 1142      |\n",
      "|    time_elapsed     | 37        |\n",
      "|    total timesteps  | 42900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=43000, episode_reward=-6958.43 +/- 711.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=43500, episode_reward=-7189.03 +/- 233.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.19e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 176       |\n",
      "|    fps              | 1143      |\n",
      "|    time_elapsed     | 38        |\n",
      "|    total timesteps  | 43900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=-7023.21 +/- 285.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=44500, episode_reward=-6475.08 +/- 308.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 180       |\n",
      "|    fps              | 1145      |\n",
      "|    time_elapsed     | 39        |\n",
      "|    total timesteps  | 44900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-6939.91 +/- 345.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=45500, episode_reward=-7280.79 +/- 928.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.28e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 184       |\n",
      "|    fps              | 1146      |\n",
      "|    time_elapsed     | 40        |\n",
      "|    total timesteps  | 45900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=-6956.21 +/- 536.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=46500, episode_reward=-6905.92 +/- 1013.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.91e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 188       |\n",
      "|    fps              | 1147      |\n",
      "|    time_elapsed     | 40        |\n",
      "|    total timesteps  | 46900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=47000, episode_reward=-6904.09 +/- 761.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=47500, episode_reward=-6604.54 +/- 738.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -6.6e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 1146     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total timesteps  | 47900    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=48000, episode_reward=-7157.86 +/- 587.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=48500, episode_reward=-7686.65 +/- 772.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.69e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 196       |\n",
      "|    fps              | 1147      |\n",
      "|    time_elapsed     | 42        |\n",
      "|    total timesteps  | 48900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=49000, episode_reward=-7053.71 +/- 1233.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=49500, episode_reward=-6560.20 +/- 788.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.56e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 200       |\n",
      "|    fps              | 1146      |\n",
      "|    time_elapsed     | 43        |\n",
      "|    total timesteps  | 49900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-6363.24 +/- 511.40\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=50500, episode_reward=-5581.29 +/- 967.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -5.58e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 204       |\n",
      "|    fps              | 1124      |\n",
      "|    time_elapsed     | 45        |\n",
      "|    total timesteps  | 50900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 6.78      |\n",
      "|    n_updates        | 224       |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=51000, episode_reward=-4417.27 +/- 555.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51500, episode_reward=-302.92 +/- 28.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -303     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 1103     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total timesteps  | 51900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.43     |\n",
      "|    n_updates        | 474      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=-2755.42 +/- 348.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=52500, episode_reward=-246.38 +/- 72.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -246     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 1085     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total timesteps  | 52900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.81     |\n",
      "|    n_updates        | 724      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=53000, episode_reward=-537.20 +/- 55.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=53500, episode_reward=-292.59 +/- 48.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -293     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 1066     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total timesteps  | 53900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29     |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=54000, episode_reward=6.26 +/- 14.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=54500, episode_reward=-156.95 +/- 142.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -157     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 1051     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total timesteps  | 54900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.59     |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-586.12 +/- 50.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=55500, episode_reward=-227.44 +/- 116.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -227     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 1034     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total timesteps  | 55900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.3      |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=15.07 +/- 6.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=56500, episode_reward=12.53 +/- 6.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 12.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 1019     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total timesteps  | 56900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 1724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=57000, episode_reward=27.30 +/- 5.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57500, episode_reward=-17.61 +/- 9.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 1006     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total timesteps  | 57900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.795    |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=-587.74 +/- 44.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=58500, episode_reward=-539.49 +/- 54.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -539     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 992      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total timesteps  | 58900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.973    |\n",
      "|    n_updates        | 2224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=59000, episode_reward=20.61 +/- 5.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=59500, episode_reward=14.28 +/- 7.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 14.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 980      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total timesteps  | 59900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.559    |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=21.03 +/- 3.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=60500, episode_reward=17.67 +/- 5.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 17.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 969      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total timesteps  | 60900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.32     |\n",
      "|    n_updates        | 2724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=61000, episode_reward=14.17 +/- 10.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=61500, episode_reward=13.37 +/- 3.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 13.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total timesteps  | 61900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.54     |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=25.12 +/- 4.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=62500, episode_reward=4.16 +/- 8.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 4.16     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 945      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total timesteps  | 62900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 3224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=63000, episode_reward=21.68 +/- 6.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=63500, episode_reward=16.36 +/- 7.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 16.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 936      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total timesteps  | 63900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.883    |\n",
      "|    n_updates        | 3474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=-58.22 +/- 95.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=64500, episode_reward=-211.61 +/- 260.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -212     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total timesteps  | 64900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.875    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=23.15 +/- 6.84\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=65500, episode_reward=-42.93 +/- 87.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -42.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 916      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total timesteps  | 65900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.857    |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=2.03 +/- 10.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=66500, episode_reward=20.53 +/- 8.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 907      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total timesteps  | 66900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.438    |\n",
      "|    n_updates        | 4224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=67000, episode_reward=12.87 +/- 17.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=67500, episode_reward=24.47 +/- 2.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total timesteps  | 67900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.498    |\n",
      "|    n_updates        | 4474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=25.39 +/- 0.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=68500, episode_reward=22.49 +/- 7.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 22.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total timesteps  | 68900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.544    |\n",
      "|    n_updates        | 4724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=69000, episode_reward=-33.53 +/- 13.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=69500, episode_reward=-22.93 +/- 5.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -22.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 886      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total timesteps  | 69900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.57     |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=21.52 +/- 8.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=70500, episode_reward=16.69 +/- 10.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 16.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total timesteps  | 70900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.37     |\n",
      "|    n_updates        | 5224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=71000, episode_reward=25.93 +/- 7.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=71500, episode_reward=25.18 +/- 5.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 874      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total timesteps  | 71900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.839    |\n",
      "|    n_updates        | 5474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=-375.94 +/- 290.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=72500, episode_reward=-46.21 +/- 75.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -46.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total timesteps  | 72900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.481    |\n",
      "|    n_updates        | 5724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=73000, episode_reward=-4.31 +/- 29.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=73500, episode_reward=22.50 +/- 8.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 22.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 863      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total timesteps  | 73900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.479    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=23.32 +/- 4.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=74500, episode_reward=7.73 +/- 15.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.73     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 858      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total timesteps  | 74900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.538    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=14.14 +/- 4.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=75500, episode_reward=27.47 +/- 3.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 27.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total timesteps  | 75900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.547    |\n",
      "|    n_updates        | 6474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=0.20 +/- 16.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=76500, episode_reward=14.85 +/- 6.86\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 14.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 848      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total timesteps  | 76900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 6724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=77000, episode_reward=0.85 +/- 37.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=77500, episode_reward=17.89 +/- 9.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 17.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 843      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total timesteps  | 77900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 6974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=21.03 +/- 5.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=78500, episode_reward=-16.45 +/- 35.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -16.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 836      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total timesteps  | 78900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.421    |\n",
      "|    n_updates        | 7224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=79000, episode_reward=-1.31 +/- 41.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=79500, episode_reward=-70.98 +/- 8.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -71      |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 830      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total timesteps  | 79900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.566    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-0.08 +/- 16.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=80500, episode_reward=-22.55 +/- 35.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -22.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total timesteps  | 80900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.773    |\n",
      "|    n_updates        | 7724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=81000, episode_reward=9.35 +/- 24.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=81500, episode_reward=-27.61 +/- 12.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -27.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 821      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total timesteps  | 81900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.871    |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=21.23 +/- 3.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=82500, episode_reward=17.12 +/- 13.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 17.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 816      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total timesteps  | 82900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.935    |\n",
      "|    n_updates        | 8224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=83000, episode_reward=-90.96 +/- 71.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=83500, episode_reward=-120.00 +/- 23.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -120     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 812      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total timesteps  | 83900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.585    |\n",
      "|    n_updates        | 8474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=-4.49 +/- 14.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=84500, episode_reward=-18.16 +/- 88.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -18.2    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 807      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total timesteps  | 84900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.592    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=16.01 +/- 14.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=85500, episode_reward=6.32 +/- 12.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 6.32     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 803      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total timesteps  | 85900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.595    |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=86000, episode_reward=-162.04 +/- 314.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=86500, episode_reward=-45.83 +/- 50.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -45.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 799      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total timesteps  | 86900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 9224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=87000, episode_reward=-21.93 +/- 52.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=87500, episode_reward=4.58 +/- 4.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 4.58     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 795      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total timesteps  | 87900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.441    |\n",
      "|    n_updates        | 9474     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=88000, episode_reward=-129.98 +/- 47.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=88500, episode_reward=-220.60 +/- 163.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -221     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total timesteps  | 88900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 9724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=89000, episode_reward=21.44 +/- 4.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=89500, episode_reward=7.05 +/- 20.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.05     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 787      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total timesteps  | 89900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.606    |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-45.72 +/- 69.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=90500, episode_reward=10.41 +/- 20.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 10.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total timesteps  | 90900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.579    |\n",
      "|    n_updates        | 10224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=91000, episode_reward=-60.63 +/- 122.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=91500, episode_reward=-42.13 +/- 98.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -42.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 780      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total timesteps  | 91900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.993    |\n",
      "|    n_updates        | 10474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=3.45 +/- 29.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=92500, episode_reward=12.92 +/- 16.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 12.9     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total timesteps  | 92900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 10724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=93000, episode_reward=-70.06 +/- 84.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=93500, episode_reward=18.31 +/- 4.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 18.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 774      |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total timesteps  | 93900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=7.10 +/- 29.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=94500, episode_reward=-138.63 +/- 117.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -139     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 772      |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total timesteps  | 94900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.501    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=8.19 +/- 4.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=95500, episode_reward=-41.75 +/- 50.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -41.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 768      |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total timesteps  | 95900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.773    |\n",
      "|    n_updates        | 11474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=-963.74 +/- 534.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=96500, episode_reward=-195.61 +/- 79.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -196     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 764      |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total timesteps  | 96900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 11724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=97000, episode_reward=-981.88 +/- 51.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=97500, episode_reward=-14.31 +/- 18.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -14.3    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 761      |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total timesteps  | 97900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.386    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=-156.14 +/- 346.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=98500, episode_reward=-7.87 +/- 14.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -7.87    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 758      |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total timesteps  | 98900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.658    |\n",
      "|    n_updates        | 12224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=99000, episode_reward=-6.79 +/- 28.91\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=99500, episode_reward=-13.94 +/- 7.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -13.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 754      |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total timesteps  | 99900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.427    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=8.37 +/- 6.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=100500, episode_reward=4.50 +/- 24.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 4.5      |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 752      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total timesteps  | 100900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.869    |\n",
      "|    n_updates        | 12724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=101000, episode_reward=-430.40 +/- 348.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=101500, episode_reward=2.92 +/- 10.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 2.92     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 750      |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total timesteps  | 101900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.414    |\n",
      "|    n_updates        | 12974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=102000, episode_reward=5.16 +/- 10.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=102500, episode_reward=9.34 +/- 11.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.34     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 747      |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total timesteps  | 102900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.356    |\n",
      "|    n_updates        | 13224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=103000, episode_reward=-320.96 +/- 324.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=103500, episode_reward=-10.95 +/- 30.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -10.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 745      |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total timesteps  | 103900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 13474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=9.44 +/- 15.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=104500, episode_reward=-1.65 +/- 20.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -1.65    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 743      |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total timesteps  | 104900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-465.00 +/- 403.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=105500, episode_reward=-186.87 +/- 200.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -187     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 741      |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total timesteps  | 105900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.469    |\n",
      "|    n_updates        | 13974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=106000, episode_reward=-198.22 +/- 46.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=106500, episode_reward=13.75 +/- 8.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 13.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 740      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total timesteps  | 106900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 14224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=107000, episode_reward=16.85 +/- 7.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=107500, episode_reward=-552.44 +/- 337.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -552     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 738      |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total timesteps  | 107900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 14474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=-286.04 +/- 229.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=108500, episode_reward=-36.05 +/- 68.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -36.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 737      |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total timesteps  | 108900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.433    |\n",
      "|    n_updates        | 14724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=109000, episode_reward=-642.92 +/- 105.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=109500, episode_reward=-127.24 +/- 83.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -127     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 735      |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total timesteps  | 109900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-178.97 +/- 163.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=110500, episode_reward=6.29 +/- 10.58\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 6.29     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 734      |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total timesteps  | 110900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.842    |\n",
      "|    n_updates        | 15224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=111000, episode_reward=-8.41 +/- 47.40\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=111500, episode_reward=-10.54 +/- 66.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -10.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 732      |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total timesteps  | 111900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.864    |\n",
      "|    n_updates        | 15474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=-41.81 +/- 101.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=112500, episode_reward=0.62 +/- 41.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 0.622    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 731      |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total timesteps  | 112900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.528    |\n",
      "|    n_updates        | 15724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=113000, episode_reward=18.19 +/- 5.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=113500, episode_reward=-5.24 +/- 21.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -5.24    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 730      |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total timesteps  | 113900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 15974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=114000, episode_reward=-744.80 +/- 359.40\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=114500, episode_reward=-23.42 +/- 38.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -23.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 729      |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total timesteps  | 114900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.597    |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-64.09 +/- 75.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=115500, episode_reward=7.24 +/- 13.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.24     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total timesteps  | 115900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 16474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=-14.27 +/- 16.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=116500, episode_reward=-18.93 +/- 4.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -18.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 726      |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total timesteps  | 116900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.228    |\n",
      "|    n_updates        | 16724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=117000, episode_reward=14.02 +/- 8.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=117500, episode_reward=-42.71 +/- 87.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -42.7    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 725      |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total timesteps  | 117900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.797    |\n",
      "|    n_updates        | 16974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=118000, episode_reward=-4.77 +/- 9.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=118500, episode_reward=9.36 +/- 12.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.36     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total timesteps  | 118900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.309    |\n",
      "|    n_updates        | 17224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=119000, episode_reward=-52.52 +/- 79.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=119500, episode_reward=-22.03 +/- 17.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -22      |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 722      |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total timesteps  | 119900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.706    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=10.04 +/- 16.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=120500, episode_reward=16.09 +/- 5.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 16.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 721      |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total timesteps  | 120900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 17724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=121000, episode_reward=12.48 +/- 9.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=121500, episode_reward=6.37 +/- 5.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 6.37     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total timesteps  | 121900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=122000, episode_reward=-1.35 +/- 7.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=122500, episode_reward=-240.62 +/- 24.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -241     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 719      |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total timesteps  | 122900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.433    |\n",
      "|    n_updates        | 18224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=123000, episode_reward=11.52 +/- 9.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=123500, episode_reward=15.80 +/- 11.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 718      |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total timesteps  | 123900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 18474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=-55.44 +/- 108.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=124500, episode_reward=9.10 +/- 9.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.1      |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total timesteps  | 124900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.363    |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=5.52 +/- 23.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=125500, episode_reward=21.42 +/- 6.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.4     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 716      |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total timesteps  | 125900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51     |\n",
      "|    n_updates        | 18974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=126000, episode_reward=-98.59 +/- 94.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=126500, episode_reward=13.77 +/- 15.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 13.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 714      |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total timesteps  | 126900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.727    |\n",
      "|    n_updates        | 19224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=127000, episode_reward=16.33 +/- 8.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=127500, episode_reward=-297.46 +/- 18.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -297     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 714      |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total timesteps  | 127900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.588    |\n",
      "|    n_updates        | 19474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=-23.31 +/- 36.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=128500, episode_reward=-107.37 +/- 88.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -107     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 713      |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total timesteps  | 128900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 19724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=129000, episode_reward=-15.64 +/- 54.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=129500, episode_reward=-99.55 +/- 150.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -99.5    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 712      |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total timesteps  | 129900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-163.29 +/- 162.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=130500, episode_reward=9.16 +/- 14.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.16     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 711      |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total timesteps  | 130900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.469    |\n",
      "|    n_updates        | 20224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=131000, episode_reward=-27.81 +/- 89.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=131500, episode_reward=-197.19 +/- 346.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -197     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 710      |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total timesteps  | 131900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 20474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=-159.58 +/- 312.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=132500, episode_reward=20.31 +/- 5.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 709      |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total timesteps  | 132900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.725    |\n",
      "|    n_updates        | 20724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=133000, episode_reward=-13.14 +/- 12.08\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=133500, episode_reward=-0.24 +/- 11.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -0.24    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 708      |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total timesteps  | 133900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.405    |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=134000, episode_reward=6.09 +/- 23.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=134500, episode_reward=-3.32 +/- 11.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -3.32    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total timesteps  | 134900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.392    |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=15.01 +/- 2.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=135500, episode_reward=10.45 +/- 5.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 10.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 706      |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total timesteps  | 135900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 21474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=-25.73 +/- 11.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=136500, episode_reward=11.12 +/- 7.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 11.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 704      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total timesteps  | 136900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.302    |\n",
      "|    n_updates        | 21724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=137000, episode_reward=15.05 +/- 10.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=137500, episode_reward=11.69 +/- 7.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 11.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 703      |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total timesteps  | 137900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.746    |\n",
      "|    n_updates        | 21974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=138000, episode_reward=11.29 +/- 11.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=138500, episode_reward=-295.66 +/- 79.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -296     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 702      |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total timesteps  | 138900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.751    |\n",
      "|    n_updates        | 22224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=139000, episode_reward=-13.13 +/- 10.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=139500, episode_reward=15.84 +/- 5.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 701      |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total timesteps  | 139900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.843    |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=15.38 +/- 11.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=140500, episode_reward=-1.47 +/- 17.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -1.47    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 700      |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total timesteps  | 140900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.736    |\n",
      "|    n_updates        | 22724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=141000, episode_reward=4.60 +/- 25.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=141500, episode_reward=17.63 +/- 10.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 17.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 699      |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total timesteps  | 141900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.42     |\n",
      "|    n_updates        | 22974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=142000, episode_reward=-19.13 +/- 9.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=142500, episode_reward=19.84 +/- 8.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 19.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 698      |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total timesteps  | 142900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.809    |\n",
      "|    n_updates        | 23224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=143000, episode_reward=-14.16 +/- 34.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=143500, episode_reward=15.54 +/- 10.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 697      |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total timesteps  | 143900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.522    |\n",
      "|    n_updates        | 23474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=0.70 +/- 16.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=144500, episode_reward=-11.43 +/- 25.95\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -11.4    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 696      |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total timesteps  | 144900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.325    |\n",
      "|    n_updates        | 23724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=14.84 +/- 7.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=145500, episode_reward=23.18 +/- 5.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total timesteps  | 145900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.303    |\n",
      "|    n_updates        | 23974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=146000, episode_reward=-485.65 +/- 261.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=146500, episode_reward=4.68 +/- 16.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 4.68     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total timesteps  | 146900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.392    |\n",
      "|    n_updates        | 24224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=147000, episode_reward=7.12 +/- 4.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=147500, episode_reward=17.73 +/- 9.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 17.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 694      |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total timesteps  | 147900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 24474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=-166.08 +/- 14.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=148500, episode_reward=21.50 +/- 3.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.5     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 693      |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total timesteps  | 148900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 24724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=149000, episode_reward=-24.70 +/- 22.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=149500, episode_reward=-258.29 +/- 64.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -258     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 692      |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total timesteps  | 149900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.532    |\n",
      "|    n_updates        | 24974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=11.76 +/- 7.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=150500, episode_reward=8.27 +/- 21.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 8.27     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 691      |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total timesteps  | 150900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.578    |\n",
      "|    n_updates        | 25224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=151000, episode_reward=9.47 +/- 6.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=151500, episode_reward=15.70 +/- 7.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 690      |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total timesteps  | 151900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.588    |\n",
      "|    n_updates        | 25474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=-38.46 +/- 114.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=152500, episode_reward=22.01 +/- 2.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 22       |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 688      |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total timesteps  | 152900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.441    |\n",
      "|    n_updates        | 25724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=153000, episode_reward=-70.99 +/- 116.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=153500, episode_reward=0.29 +/- 8.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 0.294    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 688      |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total timesteps  | 153900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.759    |\n",
      "|    n_updates        | 25974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=154000, episode_reward=13.29 +/- 16.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=154500, episode_reward=9.35 +/- 15.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.35     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 687      |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total timesteps  | 154900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.521    |\n",
      "|    n_updates        | 26224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=16.51 +/- 7.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=155500, episode_reward=7.46 +/- 10.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.46     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 687      |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total timesteps  | 155900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 26474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=156000, episode_reward=-17.21 +/- 40.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=156500, episode_reward=-2.32 +/- 12.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -2.32    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 686      |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total timesteps  | 156900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 26724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=157000, episode_reward=13.87 +/- 12.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=157500, episode_reward=15.18 +/- 11.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 686      |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total timesteps  | 157900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 26974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=158000, episode_reward=-13.25 +/- 40.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=158500, episode_reward=18.57 +/- 8.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 18.6     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 685      |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total timesteps  | 158900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.475    |\n",
      "|    n_updates        | 27224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=159000, episode_reward=12.26 +/- 17.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=159500, episode_reward=16.09 +/- 9.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 16.1     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 684      |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total timesteps  | 159900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.636    |\n",
      "|    n_updates        | 27474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=7.51 +/- 5.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=160500, episode_reward=14.29 +/- 7.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 14.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 684      |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total timesteps  | 160900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.799    |\n",
      "|    n_updates        | 27724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=161000, episode_reward=24.75 +/- 2.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=161500, episode_reward=10.72 +/- 17.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 10.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 683      |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total timesteps  | 161900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.561    |\n",
      "|    n_updates        | 27974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=162000, episode_reward=19.15 +/- 3.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=162500, episode_reward=17.96 +/- 9.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 18       |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 682      |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total timesteps  | 162900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.572    |\n",
      "|    n_updates        | 28224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=163000, episode_reward=13.31 +/- 11.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=163500, episode_reward=7.09 +/- 16.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.09     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 681      |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total timesteps  | 163900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.792    |\n",
      "|    n_updates        | 28474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=3.00 +/- 17.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=164500, episode_reward=-0.54 +/- 13.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -0.536   |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 680      |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total timesteps  | 164900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.29     |\n",
      "|    n_updates        | 28724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=15.25 +/- 3.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=165500, episode_reward=9.69 +/- 15.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.69     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 679      |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total timesteps  | 165900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 28974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=166000, episode_reward=6.38 +/- 13.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=166500, episode_reward=7.13 +/- 25.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.13     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 679      |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total timesteps  | 166900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 29224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=167000, episode_reward=-11.98 +/- 61.15\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=167500, episode_reward=-37.94 +/- 59.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -37.9    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 678      |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total timesteps  | 167900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 29474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=3.08 +/- 26.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=168500, episode_reward=-0.95 +/- 5.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -0.949   |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 677      |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total timesteps  | 168900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.292    |\n",
      "|    n_updates        | 29724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=169000, episode_reward=-90.48 +/- 118.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=169500, episode_reward=-1.81 +/- 26.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -1.81    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 677      |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total timesteps  | 169900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.698    |\n",
      "|    n_updates        | 29974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-20.78 +/- 78.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=170500, episode_reward=13.30 +/- 21.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 13.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 676      |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total timesteps  | 170900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.89     |\n",
      "|    n_updates        | 30224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=171000, episode_reward=20.94 +/- 11.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=171500, episode_reward=13.16 +/- 15.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 13.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 676      |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total timesteps  | 171900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 30474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=-19.27 +/- 32.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=172500, episode_reward=21.23 +/- 7.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 675      |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total timesteps  | 172900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 30724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=173000, episode_reward=17.53 +/- 12.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=173500, episode_reward=6.11 +/- 15.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 6.11     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 674      |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total timesteps  | 173900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 30974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=174000, episode_reward=-33.82 +/- 31.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=174500, episode_reward=-5.16 +/- 53.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -5.16    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 674      |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total timesteps  | 174900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.612    |\n",
      "|    n_updates        | 31224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=12.36 +/- 9.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=175500, episode_reward=-2.53 +/- 18.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -2.53    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 673      |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total timesteps  | 175900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 31474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=26.57 +/- 5.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=176500, episode_reward=-30.05 +/- 56.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -30.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 673      |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total timesteps  | 176900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.243    |\n",
      "|    n_updates        | 31724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=177000, episode_reward=-0.42 +/- 27.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=177500, episode_reward=-351.03 +/- 41.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -351     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 672      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total timesteps  | 177900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 31974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=178000, episode_reward=-26.10 +/- 47.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=178500, episode_reward=-11.02 +/- 38.23\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -11      |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 671      |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total timesteps  | 178900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.313    |\n",
      "|    n_updates        | 32224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=179000, episode_reward=13.18 +/- 5.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=179500, episode_reward=-1.97 +/- 37.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -1.97    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 670      |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total timesteps  | 179900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 32474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=9.96 +/- 24.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=180500, episode_reward=-0.63 +/- 30.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -0.635   |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 670      |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total timesteps  | 180900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.967    |\n",
      "|    n_updates        | 32724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=181000, episode_reward=2.92 +/- 10.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=181500, episode_reward=23.26 +/- 10.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.3     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 669      |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total timesteps  | 181900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.591    |\n",
      "|    n_updates        | 32974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=182000, episode_reward=-12.63 +/- 17.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=182500, episode_reward=-6.52 +/- 11.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -6.52    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 669      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total timesteps  | 182900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.763    |\n",
      "|    n_updates        | 33224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=183000, episode_reward=8.23 +/- 11.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=183500, episode_reward=-9.16 +/- 25.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -9.16    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 668      |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total timesteps  | 183900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 33474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=-6.35 +/- 6.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=184500, episode_reward=-7.84 +/- 37.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -7.84    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 668      |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total timesteps  | 184900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.614    |\n",
      "|    n_updates        | 33724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=12.70 +/- 5.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=185500, episode_reward=8.37 +/- 34.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 8.37     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 668      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total timesteps  | 185900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.334    |\n",
      "|    n_updates        | 33974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=186000, episode_reward=-9.30 +/- 17.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=186500, episode_reward=-3.22 +/- 41.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -3.22    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 667      |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total timesteps  | 186900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.735    |\n",
      "|    n_updates        | 34224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=187000, episode_reward=-10.60 +/- 13.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=187500, episode_reward=6.51 +/- 21.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 6.51     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 667      |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total timesteps  | 187900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.314    |\n",
      "|    n_updates        | 34474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=188000, episode_reward=15.02 +/- 11.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=188500, episode_reward=7.57 +/- 18.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.57     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 666      |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total timesteps  | 188900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.197    |\n",
      "|    n_updates        | 34724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=189000, episode_reward=9.63 +/- 8.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=189500, episode_reward=22.18 +/- 7.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 22.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 666      |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total timesteps  | 189900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.693    |\n",
      "|    n_updates        | 34974    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=21.81 +/- 7.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=190500, episode_reward=26.81 +/- 6.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 666      |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total timesteps  | 190900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.55     |\n",
      "|    n_updates        | 35224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=191000, episode_reward=8.79 +/- 24.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=191500, episode_reward=-131.37 +/- 46.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -131     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 665      |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total timesteps  | 191900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.264    |\n",
      "|    n_updates        | 35474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=18.54 +/- 6.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=192500, episode_reward=8.57 +/- 11.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 8.57     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 665      |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total timesteps  | 192900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 35724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=193000, episode_reward=-29.31 +/- 27.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=193500, episode_reward=2.35 +/- 21.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 2.35     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 665      |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total timesteps  | 193900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.377    |\n",
      "|    n_updates        | 35974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=194000, episode_reward=9.88 +/- 16.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=194500, episode_reward=-2.82 +/- 6.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -2.82    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 664      |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total timesteps  | 194900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 36224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-8.99 +/- 26.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=195500, episode_reward=20.72 +/- 5.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20.7     |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 664      |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total timesteps  | 195900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 36474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=12.87 +/- 4.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=196500, episode_reward=-28.96 +/- 43.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -29      |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 664      |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total timesteps  | 196900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.327    |\n",
      "|    n_updates        | 36724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=197000, episode_reward=10.10 +/- 14.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=197500, episode_reward=-98.96 +/- 14.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -99      |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 663      |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total timesteps  | 197900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.594    |\n",
      "|    n_updates        | 36974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=198000, episode_reward=15.87 +/- 6.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=198500, episode_reward=-14.58 +/- 6.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -14.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 663      |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total timesteps  | 198900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.331    |\n",
      "|    n_updates        | 37224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=199000, episode_reward=-8.83 +/- 11.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=199500, episode_reward=-44.55 +/- 10.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -44.6    |\n",
      "| rollout/            |          |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 663      |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total timesteps  | 199900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.857    |\n",
      "|    n_updates        | 37474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=12.29 +/- 17.54\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7fd3c6035e90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "                             log_path='./logs/', eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "\n",
    "print(\"Model not found! Starting training...\")\n",
    "policy_kwargs = dict(net_arch=[10,10])\n",
    "model = DQN('MlpPolicy', env, policy_kwargs=policy_kwargs, verbose=1, gamma=1.0, tensorboard_log=\"./logs/\")\n",
    "total_timesteps = 200000\n",
    "model.learn(total_timesteps=total_timesteps,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "\n",
    "# Load best model!\n",
    "model = DQN.load(\"./logs/best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-PRu_fXD0ENx"
   },
   "outputs": [],
   "source": [
    "# optimal policy agent as per Avellaneda\n",
    "\n",
    "def spread_func(beta, sigma, k):\n",
    "    return lambda T_t: spread(beta, sigma, T_t, k) \n",
    "\n",
    "def r_func(sigma, beta):\n",
    "    return lambda T_t, s, q: r(beta, sigma, T_t, s, q)\n",
    "    \n",
    "class AvellanedaAgent:\n",
    "    def __init__(self, beta, sigma, k):\n",
    "        self.spread_func = spread_func(beta, sigma, k)\n",
    "        self.r_func = r_func(sigma, beta)\n",
    "        \n",
    "    def act(self, observation):\n",
    "        spread = self.spread_func(observation[2])\n",
    "        r_ = self.r_func(observation[2], observation[0], observation[1])\n",
    "        \n",
    "        bid = r_ - spread/2\n",
    "        ask = r_ + spread/2\n",
    "\n",
    "        ds = observation[0] - r_\n",
    "        \n",
    "        #return spread, ds\n",
    "        return ds\n",
    "\n",
    "    def step(self,observation):\n",
    "        return self.act(observation)\n",
    "\n",
    "#agent = AvellanedaAgent(gamma, sigma, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S7FXF8L50K2V"
   },
   "outputs": [],
   "source": [
    "# symmetrical policy agent as per Avellaneda\n",
    "\n",
    "class SymmetricAgent:\n",
    "    def __init__(self, beta, sigma, k):\n",
    "        self.spread_func = spread_func(beta, sigma, k)\n",
    "        \n",
    "    def act(self, observation):\n",
    "        #spread = self.spread_func(observation[2])\n",
    "        return 0\n",
    "\n",
    "    def step(self,observation):\n",
    "        return self.act(observation)\n",
    "\n",
    "#symmetric_agent = SymmetricAgent(gamma, sigma, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_GGrBbZWz7pK"
   },
   "outputs": [],
   "source": [
    "def run_env_agent_comp(envs, agent_rl,agent_opt,agent_sym):\n",
    "    \n",
    "    env = envs[0]\n",
    "    \n",
    "    obs = env.reset()\n",
    "    bids_rl = np.zeros(env.n)\n",
    "    asks_rl = np.zeros(env.n)\n",
    "    ss_rl = np.zeros(env.n)\n",
    "    ws_rl = np.zeros(env.n)\n",
    "    qs_rl = np.zeros(env.n)\n",
    "    final = False\n",
    "    i = 0\n",
    "\n",
    "    total_reward_rl = 0.0\n",
    "    while not final:\n",
    "\n",
    "        action_rl = agent_rl.predict(obs,deterministic=True)\n",
    "        ss_rl[i] = obs[0]\n",
    "        qs_rl[i] = obs[1]\n",
    "        \n",
    "        despl = (action_rl[0]-(actions_num-1)/2)*max_abs_dif/(actions_num-1)\n",
    "        ba_spread = spread(env.beta,env.sigma,env.T-env.t,env.k)\n",
    "\n",
    "        bids_rl[i] = ss_rl[i] - despl - ba_spread/2\n",
    "        asks_rl[i] = ss_rl[i] - despl + ba_spread/2\n",
    "\n",
    "        obs, reward, final, w_rl = env.step(action_rl[0])\n",
    "        i += 1\n",
    "        total_reward_rl += reward\n",
    "\n",
    "      \n",
    "    \n",
    "\n",
    "    env = envs[1]\n",
    "    \n",
    "    obs = env.reset()\n",
    "    bids_opt = np.zeros(env.n)\n",
    "    asks_opt = np.zeros(env.n)\n",
    "    ds_opt = np.zeros(env.n)\n",
    "    spread_opt = np.zeros(env.n)\n",
    "    ss_opt = np.zeros(env.n)\n",
    "    ws_opt = np.zeros(env.n)\n",
    "    qs_opt = np.zeros(env.n)\n",
    "    final = False\n",
    "    i = 0\n",
    "\n",
    "    total_reward_opt = 0.0\n",
    "    while not final:\n",
    "        action_opt = agent_opt.step(obs)\n",
    "\n",
    "        ds_opt[i] = action_opt\n",
    "        spread_opt[i] = spread(env.beta,env.sigma,env.T-env.t,env.k)\n",
    "        \n",
    "        ss_opt[i] = obs[0]\n",
    "        qs_opt[i] = obs[1]\n",
    "\n",
    "        bids_opt[i] = ss_opt[i] - ds_opt[i] - spread_opt[i]/2\n",
    "        asks_opt[i] = ss_opt[i] - ds_opt[i] + spread_opt[i]/2\n",
    "\n",
    "        obs, reward, final, w_opt = env.step(action_opt)\n",
    "        total_reward_opt += reward\n",
    "        i += 1\n",
    "\n",
    "    env = envs[2]\n",
    "\n",
    "    obs = env.reset()\n",
    "    bids_sym = np.zeros(env.n)\n",
    "    asks_sym = np.zeros(env.n)\n",
    "    ds_sym = np.zeros(env.n)\n",
    "    spread_sym = np.zeros(env.n)\n",
    "    ss_sym = np.zeros(env.n)\n",
    "    ws_sym = np.zeros(env.n)\n",
    "    qs_sym = np.zeros(env.n)    \n",
    "    final = False\n",
    "    i = 0\n",
    "\n",
    "    total_reward_sym = 0.0\n",
    "    while not final:\n",
    "        action_sym = agent_sym.step(obs)\n",
    "\n",
    "        ds_sym[i] = action_sym\n",
    "        spread_sym[i] = spread(env.beta,env.sigma,env.T-env.t,env.k)\n",
    "        \n",
    "        ss_sym[i] = obs[0]\n",
    "        qs_sym[i] = obs[1]\n",
    "\n",
    "        bids_sym[i] = ss_sym[i] - ds_sym[i] - spread_sym[i]/2\n",
    "        asks_sym[i] = ss_sym[i] - ds_sym[i] + spread_sym[i]/2\n",
    "        \n",
    "        obs, reward, final, w_sym = env.step(action_sym)\n",
    "        i += 1\n",
    "        total_reward_sym += reward\n",
    "\n",
    "        \n",
    "    return w_rl['w'], w_opt['w'], w_sym['w'],total_reward_rl,total_reward_opt,total_reward_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pgV6nOhgAupx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/anaconda3/envs/GPU/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0%\n",
      "2.0%\n",
      "3.0%\n",
      "4.0%\n",
      "5.0%\n",
      "6.0%\n",
      "7.0%\n",
      "8.0%\n",
      "9.0%\n",
      "10.0%\n",
      "11.0%\n",
      "12.0%\n",
      "13.0%\n",
      "14.0%\n",
      "15.0%\n",
      "16.0%\n",
      "17.0%\n",
      "18.0%\n",
      "19.0%\n",
      "20.0%\n",
      "21.0%\n",
      "22.0%\n",
      "23.0%\n",
      "24.0%\n",
      "25.0%\n",
      "26.0%\n",
      "27.0%\n",
      "28.0%\n",
      "29.0%\n",
      "30.0%\n",
      "31.0%\n",
      "32.0%\n",
      "33.0%\n",
      "34.0%\n",
      "35.0%\n",
      "36.0%\n",
      "37.0%\n",
      "38.0%\n",
      "39.0%\n",
      "40.0%\n",
      "41.0%\n",
      "42.0%\n",
      "43.0%\n",
      "44.0%\n",
      "45.0%\n",
      "46.0%\n",
      "47.0%\n",
      "48.0%\n",
      "49.0%\n",
      "50.0%\n",
      "51.0%\n",
      "52.0%\n",
      "53.0%\n",
      "54.0%\n",
      "55.0%\n",
      "56.0%\n",
      "57.0%\n",
      "58.0%\n",
      "59.0%\n",
      "60.0%\n",
      "61.0%\n",
      "62.0%\n",
      "63.0%\n",
      "64.0%\n",
      "65.0%\n",
      "66.0%\n",
      "67.0%\n",
      "68.0%\n",
      "69.0%\n",
      "70.0%\n",
      "71.0%\n",
      "72.0%\n",
      "73.0%\n",
      "74.0%\n",
      "75.0%\n",
      "76.0%\n",
      "77.0%\n",
      "78.0%\n",
      "79.0%\n",
      "80.0%\n",
      "81.0%\n",
      "82.0%\n",
      "83.0%\n",
      "84.0%\n",
      "85.0%\n",
      "86.0%\n",
      "87.0%\n",
      "88.0%\n",
      "89.0%\n",
      "90.0%\n",
      "91.0%\n",
      "92.0%\n",
      "93.0%\n",
      "94.0%\n",
      "95.0%\n",
      "96.0%\n",
      "97.0%\n",
      "98.0%\n",
      "99.0%\n"
     ]
    }
   ],
   "source": [
    "number_of_sims = 1000\n",
    "\n",
    "n = int(T/dt)\n",
    "ws_rl = np.zeros(number_of_sims)\n",
    "ws_opt = np.zeros(number_of_sims)\n",
    "ws_sym = np.zeros(number_of_sims)\n",
    "tr_rl = np.zeros(number_of_sims)\n",
    "tr_opt = np.zeros(number_of_sims)\n",
    "tr_sym = np.zeros(number_of_sims)\n",
    "\n",
    "envs = [AvellanedaEnv(s0, T, dt, sigma, beta, k, A, kappa),AvellanedaEnv(s0, T, dt, sigma, beta, k, A,kappa, seed=0, is_discrete=False),AvellanedaEnv(s0, T, dt, sigma, beta, k, A,kappa, seed=0, is_discrete=False)]\n",
    "for i in range(number_of_sims):\n",
    "    if i%10 == 0:\n",
    "        print(str(i/10) + \"%\")\n",
    "    ws_rl[i], ws_opt[i], ws_sym[i], tr_rl[i], tr_opt[i], tr_sym[i] = run_env_agent_comp(envs, model,AvellanedaAgent(beta, sigma, k),SymmetricAgent(beta, sigma, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Byg9c4wIC22a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accumulated wealth histogram')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure 2 (p. 222)\n",
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([ws_opt,ws_rl], bins=30,edgecolor='black', label=['Optimum','RL Discrete'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Wealth\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5QZDlL5dN3DX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accumulated wealth histogram')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([tr_opt,tr_sym,tr_rl], bins=30,edgecolor='black', label=['Optimum', 'Symmetric','RL Discrete'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Total Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")\n",
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([tr_opt,tr_rl], bins=30,edgecolor='black', label=['Optimum','RL Discrete'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Total Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LUl_ON_bDS1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimo:\n",
      "47.79761695404737\n",
      "6.099978058681764\n",
      "7.83570309503321\n",
      "Simetrico:\n",
      "57.676984427753716\n",
      "11.86348257940186\n",
      "4.8617245435076715\n",
      "RL:\n",
      "54.57863012978638\n",
      "7.894426603577656\n",
      "6.913564831301621\n",
      "\n",
      "Optimum utility function value: \t-2.6283680458275698e-09\n",
      "Symmetric utility function value: \t-4.34167929750502e-06\n",
      "RL utility function value: \t\t-8.124943202617841e-10\n",
      "\n",
      "Utility function improvement:\t\t2.235 times\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimo:\")\n",
    "print(np.mean(ws_opt))\n",
    "print(np.std(ws_opt))\n",
    "print(np.mean(ws_opt)/np.std(ws_opt))\n",
    "print(\"Simetrico:\")\n",
    "print(np.mean(ws_sym))\n",
    "print(np.std(ws_sym))\n",
    "print(np.mean(ws_sym)/np.std(ws_sym))\n",
    "print(\"RL:\")\n",
    "print(np.mean(ws_rl))\n",
    "print(np.std(ws_rl))\n",
    "print(np.mean(ws_rl)/np.std(ws_rl))\n",
    "\n",
    "print()\n",
    "\n",
    "utility_avellaneda = np.mean(-np.exp(-beta*ws_opt))\n",
    "utility_rl = np.mean(-np.exp(-beta*ws_rl))\n",
    "\n",
    "print(\"Optimum utility function value: \\t{}\".format(utility_avellaneda))\n",
    "print(\"Symmetric utility function value: \\t{}\".format(np.mean(-np.exp(-beta*ws_sym))))\n",
    "print(\"RL utility function value: \\t\\t{}\".format(utility_rl))\n",
    "\n",
    "print()\n",
    "improvement = utility_avellaneda / utility_rl - 1\n",
    "print(\"Utility function improvement:\\t\\t{:.3f} times\".format(improvement))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UJqDqpVIeGti"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimo:\n",
      "22.46050972128678\n",
      "3.4646472377108304\n",
      "6.482769580930536\n",
      "Simetrico:\n",
      "-7.172303914746957\n",
      "42.1491264960118\n",
      "-0.1701649479123988\n",
      "RL:\n",
      "20.62823448692836\n",
      "7.272589642704975\n",
      "2.8364359190292316\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimo:\")\n",
    "print(np.mean(tr_opt))\n",
    "print(np.std(tr_opt))\n",
    "print(np.mean(tr_opt)/np.std(tr_opt))\n",
    "\n",
    "print(\"Simetrico:\")\n",
    "print(np.mean(tr_sym))\n",
    "print(np.std(tr_sym))\n",
    "print(np.mean(tr_sym)/np.std(tr_sym))\n",
    "\n",
    "print(\"RL:\")\n",
    "print(np.mean(tr_rl))\n",
    "print(np.std(tr_rl))\n",
    "print(np.mean(tr_rl)/np.std(tr_rl))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sim_corregida.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
