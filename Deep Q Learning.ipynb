{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QzeQrzMu1EPM"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "# make the simulation into an RL environment:\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import matplotlib.pyplot as plt\n",
    "from runstats import *\n",
    "import runstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2M5Wrp30Si_",
    "outputId": "e581e98b-3352-435a-9036-4b14a1de1ba4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\anaconda3\\envs\\market-making-rl\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# MS: Using a discrete action space similar to the Market Making via Reinforcement Learning paper (https://arxiv.org/pdf/1804.04216.pdf, Section 3 - p.3)\n",
    "actions_num = 21   #MS: So the range of possibilities goes from 0.3% to 3% from TOB\n",
    "max_abs_dif = 4\n",
    "max_abs_spread = 20\n",
    "\n",
    "\n",
    "s0 = 100\n",
    "T = 1. # Total time.\n",
    "sigma = 2.  # Standard deviation.\n",
    "dt = .005  # Time step.\n",
    "beta = 0.5\n",
    "kappa = beta * 2\n",
    "k = 1.5\n",
    "A = 137.45\n",
    "\n",
    "def spread(beta, sigma, T_t, k):\n",
    "    return beta*sigma**2*(T_t) + 2/beta*np.log(1+beta/k)\n",
    "\n",
    "def r(beta, sigma, T_t, s, q):\n",
    "    return s - q*beta*sigma**2*(T_t)\n",
    "\n",
    "def l(A, k, d):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "      A : float\n",
    "        in Avellaneda A = \\lambda/\\alpha, where alpha is as above,\n",
    "        and lambda is the constant frequency of market buy and sell orders.\n",
    "      k : float\n",
    "        in Avellaneda k = alpha*K, where alpha ~ 1.5, \n",
    "        and K is such that \\delta p ~ Kln(Q) for a market order of size Q\n",
    "      d : float\n",
    "        in Avellaneda, d=distance to the mid price\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    \n",
    "      l : float:\n",
    "        in Avellaneda, l = lambda = Poisson intensity at which our agentâ€™s orders are\n",
    "        executed.\n",
    "    '''\n",
    "    return A*np.exp(-k*d) \n",
    "    #JK: eq. (12)    \n",
    "\n",
    "\n",
    "class AvellanedaEnv:\n",
    "    def __init__(self, s0, T, dt, sigma, beta, k, A, kappa, seed=0, is_discrete=True):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        s : float\n",
    "            Initial value of future/stock price.\n",
    "        b : float\n",
    "            Initial value of 'brecha'.\n",
    "        T : float\n",
    "            Total time.\n",
    "        dt : float\n",
    "            Time subdivision.\n",
    "        sigma : float\n",
    "            price volatility.\n",
    "        gamma : float\n",
    "            discount factor.\n",
    "        k : float\n",
    "            in Avellaneda k = alpha*K, where alpha ~ 1.5, \n",
    "            and K is such that \\delta p ~ Kln(Q) for a market order of size Q\n",
    "        A : float\n",
    "            in Avellaneda A = \\lambda/\\alpha, where alpha is as above,\n",
    "            and lambda is the constant frequency of market buy and sell orders.\n",
    "    \n",
    "        '''\n",
    "        self.s0 = s0\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.sigma = sigma\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        self.A = A\n",
    "        self.sqrtdt = np.sqrt(dt)\n",
    "        self.kappa = kappa\n",
    "        self.is_discrete = is_discrete\n",
    "        self.stats = runstats.ExponentialStatistics(decay=0.999)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # observation space: s (price), q, T-t (time remaining)\n",
    "        self.observation_space = gym.spaces.Box(low=np.array([0.0, -math.inf, 0.0]),\n",
    "                                     high=np.array([math.inf, math.inf,T]),\n",
    "                                     dtype=np.float32)\n",
    "        # action space: spread, ds\n",
    "        self.action_space = gym.spaces.Discrete(actions_num)\n",
    "        self.reward_range = (-math.inf,math.inf)\n",
    "        \n",
    "        self.metadata = None # useless field\n",
    "        \n",
    "    def reset(self,seed=0):\n",
    "        self.s = self.s0\n",
    "        self.q = 0.0\n",
    "        self.t = 0.0\n",
    "        self.w = 0.0\n",
    "        self.n = int(T/dt)\n",
    "        self.c_ = 0.0\n",
    "        return np.array((self.s,self.q,self.T))\n",
    "        \n",
    "    def step(self, action):\n",
    "        if self.is_discrete:\n",
    "            despl = (action-(actions_num-1)/2)*max_abs_dif/(actions_num-1)\n",
    "        else:\n",
    "            despl = action\n",
    "        ba_spread = spread(self.beta,self.sigma,self.T-self.t,self.k)\n",
    "\n",
    "        bid = self.s - despl - ba_spread/2\n",
    "        ask = self.s - despl + ba_spread/2\n",
    "                \n",
    "        db = self.s - bid\n",
    "        da = ask - self.s\n",
    "        \n",
    "        lb = l(A, k, db)\n",
    "        la = l(A, k, da)\n",
    "        \n",
    "        dnb = 1 if np.random.uniform() <= lb * self.dt else 0\n",
    "        dna = 1 if np.random.uniform() <= la * self.dt else 0\n",
    "        self.q += dnb - dna\n",
    "\n",
    "        self.c_ += -dnb * bid + dna * ask # cash\n",
    "\n",
    "        self.s += self.sigma * self.sqrtdt *(1 if np.random.uniform() < 0.5 else -1)\n",
    "\n",
    "        previous_w = self.w\n",
    "        self.w = self.c_ + self.q * self.s\n",
    "                \n",
    "        dw = (self.w - previous_w)\n",
    "        self.stats.push(dw)\n",
    "        #reward =  np.exp(-self.gamma*previous_w) - np.exp(-self.gamma*self.w) - 1/(self.n)\n",
    "        \n",
    "        #if self.t >= self.T:\n",
    "        reward = dw - self.kappa/2 * (dw - self.stats.mean())**2\n",
    "        \n",
    "        #if self.t >= self.T - self.dt:\n",
    "            #print(\"sum of dw: \" + str(sum(self.ws)))\n",
    "            #print(\"sum of kappa/2 * (dw - mu)**2: \" + str(sum(self.rews)))\n",
    "        \n",
    "        self.t += self.dt\n",
    "\n",
    "            \n",
    "        return np.array((self.s,self.q,self.T-self.t)), reward, self.t >= self.T, {'w':self.w}\n",
    "    \n",
    "env = AvellanedaEnv(s0, T, dt, sigma, beta, k, A,kappa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 14624."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "ohfqOsj10psv",
    "outputId": "650c7370-1b20-42d5-c23f-4fb073ae6e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found! Starting training...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/DQN_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\anaconda3\\envs\\market-making-rl\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500, episode_reward=-6561.73 +/- 704.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.56e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 225       |\n",
      "|    ep_rew_mean      | -189      |\n",
      "|    exploration rate | 0.957     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 3447      |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total timesteps  | 900       |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=-5870.10 +/- 843.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1500, episode_reward=-6868.27 +/- 348.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.87e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 238       |\n",
      "|    ep_rew_mean      | -174      |\n",
      "|    exploration rate | 0.91      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 2620      |\n",
      "|    time_elapsed     | 0         |\n",
      "|    total timesteps  | 1900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-6690.53 +/- 805.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=2500, episode_reward=-6445.86 +/- 370.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.45e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 242       |\n",
      "|    ep_rew_mean      | -240      |\n",
      "|    exploration rate | 0.862     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 2408      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total timesteps  | 2900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-6312.80 +/- 606.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=3500, episode_reward=-6735.88 +/- 528.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.74e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 244       |\n",
      "|    ep_rew_mean      | -221      |\n",
      "|    exploration rate | 0.815     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 2343      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total timesteps  | 3900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-6338.91 +/- 675.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=-6384.18 +/- 675.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.38e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 245       |\n",
      "|    ep_rew_mean      | -204      |\n",
      "|    exploration rate | 0.767     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 2322      |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total timesteps  | 4900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-6819.62 +/- 506.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=5500, episode_reward=-7010.05 +/- 1199.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.01e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 246       |\n",
      "|    ep_rew_mean      | -202      |\n",
      "|    exploration rate | 0.72      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 2284      |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total timesteps  | 5900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-6708.51 +/- 491.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=6500, episode_reward=-6765.37 +/- 990.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.77e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 246       |\n",
      "|    ep_rew_mean      | -213      |\n",
      "|    exploration rate | 0.672     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 2257      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total timesteps  | 6900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-6421.87 +/- 383.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=7500, episode_reward=-6611.39 +/- 516.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.61e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 247       |\n",
      "|    ep_rew_mean      | -239      |\n",
      "|    exploration rate | 0.625     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 2236      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total timesteps  | 7900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-6547.22 +/- 271.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=8500, episode_reward=-6539.85 +/- 705.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.54e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 247       |\n",
      "|    ep_rew_mean      | -226      |\n",
      "|    exploration rate | 0.577     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 2220      |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total timesteps  | 8900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-6994.98 +/- 114.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=9500, episode_reward=-6629.01 +/- 577.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.63e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 248       |\n",
      "|    ep_rew_mean      | -222      |\n",
      "|    exploration rate | 0.53      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 2215      |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total timesteps  | 9900      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-6383.81 +/- 637.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=10500, episode_reward=-6194.42 +/- 497.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.19e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 248       |\n",
      "|    ep_rew_mean      | -222      |\n",
      "|    exploration rate | 0.482     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 2223      |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total timesteps  | 10900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=-5952.27 +/- 608.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=11500, episode_reward=-6090.89 +/- 251.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.09e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 248       |\n",
      "|    ep_rew_mean      | -222      |\n",
      "|    exploration rate | 0.435     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 2232      |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total timesteps  | 11900     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=12000, episode_reward=-6501.96 +/- 385.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=12500, episode_reward=-6349.09 +/- 385.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.35e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 248       |\n",
      "|    ep_rew_mean      | -217      |\n",
      "|    exploration rate | 0.387     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 2243      |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total timesteps  | 12900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=13000, episode_reward=-6695.84 +/- 676.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=-6536.51 +/- 1026.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.54e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 248       |\n",
      "|    ep_rew_mean      | -220      |\n",
      "|    exploration rate | 0.34      |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 2241      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total timesteps  | 13900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=14000, episode_reward=-6693.37 +/- 392.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=14500, episode_reward=-6956.69 +/- 656.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.96e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 248       |\n",
      "|    ep_rew_mean      | -219      |\n",
      "|    exploration rate | 0.292     |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 2233      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total timesteps  | 14900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-7160.13 +/- 754.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=15500, episode_reward=-6674.58 +/- 694.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.67e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 248       |\n",
      "|    ep_rew_mean      | -214      |\n",
      "|    exploration rate | 0.245     |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 2236      |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total timesteps  | 15900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=16000, episode_reward=-6563.14 +/- 569.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=16500, episode_reward=-6226.75 +/- 628.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.23e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -213      |\n",
      "|    exploration rate | 0.197     |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 2238      |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total timesteps  | 16900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=17000, episode_reward=-6405.63 +/- 366.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=17500, episode_reward=-6604.62 +/- 679.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -6.6e+03 |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 249      |\n",
      "|    ep_rew_mean      | -215     |\n",
      "|    exploration rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 2231     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total timesteps  | 17900    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=18000, episode_reward=-6414.92 +/- 317.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=18500, episode_reward=-5688.41 +/- 796.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -5.69e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -214      |\n",
      "|    exploration rate | 0.102     |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 2223      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total timesteps  | 18900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=19000, episode_reward=-6702.14 +/- 680.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=19500, episode_reward=-6388.34 +/- 322.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.39e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -216      |\n",
      "|    exploration rate | 0.0547    |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 2208      |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total timesteps  | 19900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-6291.30 +/- 395.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=20500, episode_reward=-6219.19 +/- 814.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.22e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -215      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 2200      |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total timesteps  | 20900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=21000, episode_reward=-6591.48 +/- 458.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=21500, episode_reward=-6579.59 +/- 928.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.58e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -215      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 2197      |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total timesteps  | 21900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=22000, episode_reward=-6460.30 +/- 752.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=22500, episode_reward=-6130.64 +/- 797.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.13e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -214      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 92        |\n",
      "|    fps              | 2193      |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total timesteps  | 22900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=23000, episode_reward=-6945.51 +/- 630.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=23500, episode_reward=-6488.32 +/- 771.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.49e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -210      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 2190      |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total timesteps  | 23900     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=24000, episode_reward=-6298.28 +/- 589.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=24500, episode_reward=-6311.35 +/- 913.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.31e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 249       |\n",
      "|    ep_rew_mean      | -209      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 2185      |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total timesteps  | 24900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-5736.54 +/- 477.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=25500, episode_reward=-6652.32 +/- 837.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.65e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -209      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 2184      |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total timesteps  | 25900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=26000, episode_reward=-6520.44 +/- 432.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=26500, episode_reward=-6290.78 +/- 824.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.29e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -211      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 2183      |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total timesteps  | 26900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=27000, episode_reward=-6529.14 +/- 825.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=27500, episode_reward=-7087.90 +/- 460.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -7.09e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -203      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 2179      |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total timesteps  | 27900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=28000, episode_reward=-7066.99 +/- 635.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=28500, episode_reward=-6283.81 +/- 660.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.28e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -202      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 2179      |\n",
      "|    time_elapsed     | 13        |\n",
      "|    total timesteps  | 28900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=29000, episode_reward=-6654.12 +/- 428.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=29500, episode_reward=-6048.92 +/- 865.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.05e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -202      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 120       |\n",
      "|    fps              | 2182      |\n",
      "|    time_elapsed     | 13        |\n",
      "|    total timesteps  | 29900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-6256.61 +/- 473.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=30500, episode_reward=-6383.63 +/- 528.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.38e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -200      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 124       |\n",
      "|    fps              | 2184      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total timesteps  | 30900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=31000, episode_reward=-6382.61 +/- 645.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=31500, episode_reward=-6686.89 +/- 332.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.69e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -196      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 128       |\n",
      "|    fps              | 2187      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total timesteps  | 31900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=-7040.13 +/- 772.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=32500, episode_reward=-6166.92 +/- 400.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.17e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -187      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 132       |\n",
      "|    fps              | 2185      |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total timesteps  | 32900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=33000, episode_reward=-6837.58 +/- 998.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=33500, episode_reward=-6758.82 +/- 668.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.76e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -187      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 136       |\n",
      "|    fps              | 2184      |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total timesteps  | 33900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=34000, episode_reward=-6776.63 +/- 876.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=34500, episode_reward=-6760.15 +/- 594.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.76e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -187      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 140       |\n",
      "|    fps              | 2180      |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total timesteps  | 34900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-6520.70 +/- 701.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=35500, episode_reward=-6380.61 +/- 598.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.38e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -190      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 144       |\n",
      "|    fps              | 2179      |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total timesteps  | 35900     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=36000, episode_reward=-6386.76 +/- 696.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=36500, episode_reward=-5923.78 +/- 535.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -5.92e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -188      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 148       |\n",
      "|    fps              | 2177      |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total timesteps  | 36900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=37000, episode_reward=-6964.03 +/- 394.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=37500, episode_reward=-6430.88 +/- 569.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.43e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -187      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 152       |\n",
      "|    fps              | 2176      |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total timesteps  | 37900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=38000, episode_reward=-6900.25 +/- 313.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=38500, episode_reward=-6372.39 +/- 364.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.37e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -183      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 156       |\n",
      "|    fps              | 2176      |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total timesteps  | 38900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=39000, episode_reward=-6615.60 +/- 329.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=39500, episode_reward=-6179.79 +/- 955.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.18e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -183      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 160       |\n",
      "|    fps              | 2176      |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total timesteps  | 39900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-7026.19 +/- 980.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=40500, episode_reward=-6816.22 +/- 940.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.82e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -187      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 164       |\n",
      "|    fps              | 2177      |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total timesteps  | 40900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=41000, episode_reward=-6511.32 +/- 195.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=41500, episode_reward=-6338.30 +/- 475.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.34e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -188      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 168       |\n",
      "|    fps              | 2175      |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total timesteps  | 41900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=42000, episode_reward=-6418.19 +/- 412.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=42500, episode_reward=-6881.81 +/- 367.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.88e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -183      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 172       |\n",
      "|    fps              | 2174      |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total timesteps  | 42900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=43000, episode_reward=-6566.25 +/- 365.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=43500, episode_reward=-6653.77 +/- 598.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.65e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -182      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 176       |\n",
      "|    fps              | 2175      |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total timesteps  | 43900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=44000, episode_reward=-6883.83 +/- 463.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=44500, episode_reward=-6192.23 +/- 321.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.19e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -185      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 180       |\n",
      "|    fps              | 2174      |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total timesteps  | 44900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-6341.31 +/- 767.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=45500, episode_reward=-6278.73 +/- 801.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.28e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -183      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 184       |\n",
      "|    fps              | 2175      |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total timesteps  | 45900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=46000, episode_reward=-6385.65 +/- 627.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=46500, episode_reward=-6306.59 +/- 668.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.31e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -181      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 188       |\n",
      "|    fps              | 2178      |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total timesteps  | 46900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=47000, episode_reward=-6259.94 +/- 687.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=47500, episode_reward=-6301.60 +/- 659.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -6.3e+03 |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -180     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 2176     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total timesteps  | 47900    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=48000, episode_reward=-6743.31 +/- 393.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=48500, episode_reward=-6549.03 +/- 379.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.55e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -187      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 196       |\n",
      "|    fps              | 2178      |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total timesteps  | 48900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=49000, episode_reward=-6533.44 +/- 517.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=49500, episode_reward=-6107.41 +/- 514.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -6.11e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -190      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 200       |\n",
      "|    fps              | 2178      |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total timesteps  | 49900     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-6139.47 +/- 567.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=50500, episode_reward=-4801.15 +/- 324.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -4.8e+03 |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -382     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 2142     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total timesteps  | 50900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 224      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=51000, episode_reward=-4156.14 +/- 224.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51500, episode_reward=-3874.78 +/- 329.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -3.87e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -530      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 208       |\n",
      "|    fps              | 2106      |\n",
      "|    time_elapsed     | 24        |\n",
      "|    total timesteps  | 51900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.49      |\n",
      "|    n_updates        | 474       |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=52000, episode_reward=-124.04 +/- 22.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=52500, episode_reward=-669.83 +/- 81.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -670     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -571     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 2070     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total timesteps  | 52900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.49     |\n",
      "|    n_updates        | 724      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=53000, episode_reward=-2311.95 +/- 522.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=53500, episode_reward=-2737.77 +/- 641.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -2.74e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -664      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 216       |\n",
      "|    fps              | 2038      |\n",
      "|    time_elapsed     | 26        |\n",
      "|    total timesteps  | 53900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.64      |\n",
      "|    n_updates        | 974       |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=54000, episode_reward=-5772.75 +/- 1311.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=54500, episode_reward=-12636.88 +/- 1387.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.26e+04 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -932      |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 220       |\n",
      "|    fps              | 2008      |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total timesteps  | 54900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.19      |\n",
      "|    n_updates        | 1224      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-13712.29 +/- 2223.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=55500, episode_reward=-150.94 +/- 13.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -151     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -982     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 1982     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total timesteps  | 55900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=56000, episode_reward=-196.19 +/- 34.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=56500, episode_reward=25.34 +/- 4.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 1958     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total timesteps  | 56900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.76     |\n",
      "|    n_updates        | 1724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=57000, episode_reward=-29.99 +/- 15.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=57500, episode_reward=-1529.61 +/- 533.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.53e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 232       |\n",
      "|    fps              | 1934      |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total timesteps  | 57900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.955     |\n",
      "|    n_updates        | 1974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=58000, episode_reward=-76.75 +/- 71.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=58500, episode_reward=-2027.56 +/- 832.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -2.03e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 236       |\n",
      "|    fps              | 1912      |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total timesteps  | 58900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.759     |\n",
      "|    n_updates        | 2224      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=59000, episode_reward=-1413.91 +/- 538.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=59500, episode_reward=-1095.14 +/- 1141.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.1e+03  |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 240       |\n",
      "|    fps              | 1889      |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total timesteps  | 59900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.9       |\n",
      "|    n_updates        | 2474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-1558.33 +/- 1105.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=60500, episode_reward=14.96 +/- 10.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | 15        |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 244       |\n",
      "|    fps              | 1867      |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total timesteps  | 60900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.42      |\n",
      "|    n_updates        | 2724      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=61000, episode_reward=-122.75 +/- 157.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=61500, episode_reward=-127.05 +/- 125.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -127      |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.05e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 248       |\n",
      "|    fps              | 1848      |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total timesteps  | 61900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.16      |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=62000, episode_reward=-135.28 +/- 133.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=62500, episode_reward=-186.44 +/- 167.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -186      |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 252       |\n",
      "|    fps              | 1830      |\n",
      "|    time_elapsed     | 34        |\n",
      "|    total timesteps  | 62900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.48      |\n",
      "|    n_updates        | 3224      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=63000, episode_reward=-46.85 +/- 27.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=63500, episode_reward=-255.88 +/- 108.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -256      |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 256       |\n",
      "|    fps              | 1811      |\n",
      "|    time_elapsed     | 35        |\n",
      "|    total timesteps  | 63900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.15      |\n",
      "|    n_updates        | 3474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=-127.19 +/- 62.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=64500, episode_reward=-582.14 +/- 951.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -582      |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 260       |\n",
      "|    fps              | 1795      |\n",
      "|    time_elapsed     | 36        |\n",
      "|    total timesteps  | 64900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.32      |\n",
      "|    n_updates        | 3724      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-2326.75 +/- 2500.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=65500, episode_reward=-1292.50 +/- 800.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.29e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.17e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 264       |\n",
      "|    fps              | 1779      |\n",
      "|    time_elapsed     | 37        |\n",
      "|    total timesteps  | 65900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.394     |\n",
      "|    n_updates        | 3974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=66000, episode_reward=-209.00 +/- 409.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=66500, episode_reward=-1630.44 +/- 3220.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.63e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.2e+03  |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 268       |\n",
      "|    fps              | 1763      |\n",
      "|    time_elapsed     | 37        |\n",
      "|    total timesteps  | 66900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.566     |\n",
      "|    n_updates        | 4224      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=67000, episode_reward=-803.08 +/- 1113.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=67500, episode_reward=-1874.83 +/- 1119.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.87e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.3e+03  |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 272       |\n",
      "|    fps              | 1748      |\n",
      "|    time_elapsed     | 38        |\n",
      "|    total timesteps  | 67900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.05      |\n",
      "|    n_updates        | 4474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=68000, episode_reward=-2277.73 +/- 237.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=68500, episode_reward=-1144.46 +/- 159.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.14e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.37e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 276       |\n",
      "|    fps              | 1733      |\n",
      "|    time_elapsed     | 39        |\n",
      "|    total timesteps  | 68900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.53      |\n",
      "|    n_updates        | 4724      |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=69000, episode_reward=-327.35 +/- 621.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=69500, episode_reward=-944.75 +/- 277.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -945      |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.36e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 280       |\n",
      "|    fps              | 1720      |\n",
      "|    time_elapsed     | 40        |\n",
      "|    total timesteps  | 69900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.757     |\n",
      "|    n_updates        | 4974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-525.55 +/- 395.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=70500, episode_reward=-1140.45 +/- 663.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.14e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.37e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 284       |\n",
      "|    fps              | 1706      |\n",
      "|    time_elapsed     | 41        |\n",
      "|    total timesteps  | 70900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 4.21      |\n",
      "|    n_updates        | 5224      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=71000, episode_reward=-12.07 +/- 5.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=71500, episode_reward=-58.07 +/- 30.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -58.1     |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.36e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 288       |\n",
      "|    fps              | 1695      |\n",
      "|    time_elapsed     | 42        |\n",
      "|    total timesteps  | 71900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.48      |\n",
      "|    n_updates        | 5474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=72000, episode_reward=-82.87 +/- 17.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=72500, episode_reward=-65.02 +/- 64.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -65       |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.36e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 292       |\n",
      "|    fps              | 1683      |\n",
      "|    time_elapsed     | 43        |\n",
      "|    total timesteps  | 72900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.01      |\n",
      "|    n_updates        | 5724      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=73000, episode_reward=-64.96 +/- 66.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=73500, episode_reward=-1.81 +/- 9.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.81     |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.36e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 296       |\n",
      "|    fps              | 1668      |\n",
      "|    time_elapsed     | 44        |\n",
      "|    total timesteps  | 73900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.21      |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=74000, episode_reward=-97.86 +/- 18.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=74500, episode_reward=-1154.39 +/- 119.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -1.15e+03 |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.36e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 300       |\n",
      "|    fps              | 1655      |\n",
      "|    time_elapsed     | 45        |\n",
      "|    total timesteps  | 74900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.803     |\n",
      "|    n_updates        | 6224      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-100.14 +/- 93.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=75500, episode_reward=-92.47 +/- 61.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -92.5     |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.17e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 304       |\n",
      "|    fps              | 1646      |\n",
      "|    time_elapsed     | 46        |\n",
      "|    total timesteps  | 75900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 0.815     |\n",
      "|    n_updates        | 6474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=76000, episode_reward=-107.22 +/- 63.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=76500, episode_reward=-129.93 +/- 62.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 200       |\n",
      "|    mean_reward      | -130      |\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 250       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 308       |\n",
      "|    fps              | 1638      |\n",
      "|    time_elapsed     | 46        |\n",
      "|    total timesteps  | 76900     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.05      |\n",
      "|    n_updates        | 6724      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=77000, episode_reward=-85.63 +/- 53.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=77500, episode_reward=-64.16 +/- 43.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -64.2    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -973     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 1626     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total timesteps  | 77900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.918    |\n",
      "|    n_updates        | 6974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=78000, episode_reward=-460.94 +/- 182.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=78500, episode_reward=-22.36 +/- 3.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -22.4    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -890     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 1615     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total timesteps  | 78900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.34     |\n",
      "|    n_updates        | 7224     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=79000, episode_reward=-34.84 +/- 40.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=79500, episode_reward=-105.90 +/- 55.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -106     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -620     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 1605     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total timesteps  | 79900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.93     |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-76.53 +/- 40.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=80500, episode_reward=-6.75 +/- 6.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -6.75    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -568     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 1595     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total timesteps  | 80900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 7724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=81000, episode_reward=-20.61 +/- 13.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=81500, episode_reward=0.16 +/- 7.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 0.156    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -539     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 1586     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total timesteps  | 81900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.726    |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=82000, episode_reward=-52.44 +/- 13.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=82500, episode_reward=-206.66 +/- 258.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -207     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -520     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 1578     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total timesteps  | 82900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.965    |\n",
      "|    n_updates        | 8224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=83000, episode_reward=5.98 +/- 3.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=83500, episode_reward=-41.25 +/- 10.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -41.2    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -507     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 1572     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total timesteps  | 83900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.626    |\n",
      "|    n_updates        | 8474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=84000, episode_reward=19.26 +/- 2.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=84500, episode_reward=-0.50 +/- 9.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -0.504   |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -466     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 1565     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total timesteps  | 84900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=1.11 +/- 2.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=85500, episode_reward=-17.58 +/- 11.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -17.6    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -457     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 1557     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total timesteps  | 85900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.987    |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=86000, episode_reward=2.51 +/- 9.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=86500, episode_reward=-11.27 +/- 22.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -11.3    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -456     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 1550     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total timesteps  | 86900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 9224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=87000, episode_reward=-0.32 +/- 11.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=87500, episode_reward=-7.52 +/- 4.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -7.52    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -436     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 1542     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total timesteps  | 87900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.611    |\n",
      "|    n_updates        | 9474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=88000, episode_reward=12.97 +/- 5.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=88500, episode_reward=11.54 +/- 3.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 11.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -428     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 1534     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total timesteps  | 88900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.06     |\n",
      "|    n_updates        | 9724     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=89000, episode_reward=8.25 +/- 7.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=89500, episode_reward=5.73 +/- 13.06\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 5.73     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -420     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 1526     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total timesteps  | 89900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.58     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=19.34 +/- 6.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=90500, episode_reward=-25.69 +/- 8.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -25.7    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -304     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 1520     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total timesteps  | 90900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.827    |\n",
      "|    n_updates        | 10224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=91000, episode_reward=-17.45 +/- 6.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=91500, episode_reward=-0.67 +/- 9.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -0.668   |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -267     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 1514     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total timesteps  | 91900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5        |\n",
      "|    n_updates        | 10474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=92000, episode_reward=-8.70 +/- 6.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=92500, episode_reward=-12.58 +/- 10.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -12.6    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -169     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 1508     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total timesteps  | 92900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 10724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=93000, episode_reward=11.19 +/- 5.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=93500, episode_reward=-106.27 +/- 233.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -106     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -99.2    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 1502     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total timesteps  | 93900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.42     |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=94000, episode_reward=3.57 +/- 4.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=94500, episode_reward=15.11 +/- 5.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -89.7    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 1497     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total timesteps  | 94900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=9.33 +/- 4.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=95500, episode_reward=9.90 +/- 9.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.9      |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -79      |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 1492     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total timesteps  | 95900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 11474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=4.77 +/- 4.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=96500, episode_reward=10.75 +/- 4.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 10.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -77.7    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 1487     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total timesteps  | 96900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.526    |\n",
      "|    n_updates        | 11724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=97000, episode_reward=15.42 +/- 3.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=97500, episode_reward=12.91 +/- 5.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 12.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -73.8    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 1482     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total timesteps  | 97900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.782    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=98000, episode_reward=12.25 +/- 6.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=98500, episode_reward=23.41 +/- 4.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -61      |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 1477     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total timesteps  | 98900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.692    |\n",
      "|    n_updates        | 12224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=99000, episode_reward=15.45 +/- 4.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=99500, episode_reward=6.07 +/- 8.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 6.07     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -48      |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 1471     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total timesteps  | 99900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.649    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=100000, episode_reward=24.34 +/- 1.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=100500, episode_reward=7.52 +/- 4.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.52     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -43.1    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 1467     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total timesteps  | 100900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 12724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=101000, episode_reward=25.40 +/- 2.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=101500, episode_reward=25.40 +/- 6.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -38      |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 1461     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total timesteps  | 101900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.489    |\n",
      "|    n_updates        | 12974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=102000, episode_reward=3.51 +/- 8.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=102500, episode_reward=24.92 +/- 1.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -33.2    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 1456     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total timesteps  | 102900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.536    |\n",
      "|    n_updates        | 13224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=103000, episode_reward=18.89 +/- 2.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=103500, episode_reward=19.26 +/- 3.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 19.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -17.7    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 1451     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total timesteps  | 103900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.437    |\n",
      "|    n_updates        | 13474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=104000, episode_reward=23.79 +/- 4.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=104500, episode_reward=10.67 +/- 6.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 10.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 1446     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total timesteps  | 104900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-19.98 +/- 4.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=105500, episode_reward=26.50 +/- 2.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -9.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 1441     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total timesteps  | 105900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.435    |\n",
      "|    n_updates        | 13974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=106000, episode_reward=23.34 +/- 5.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=106500, episode_reward=6.94 +/- 7.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 6.94     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 1437     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total timesteps  | 106900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 14224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=107000, episode_reward=22.22 +/- 3.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=107500, episode_reward=28.83 +/- 4.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 28.8     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -7.07    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 1434     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total timesteps  | 107900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.847    |\n",
      "|    n_updates        | 14474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=108000, episode_reward=21.01 +/- 4.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=108500, episode_reward=28.13 +/- 3.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 28.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -5.77    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 1430     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total timesteps  | 108900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.589    |\n",
      "|    n_updates        | 14724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=109000, episode_reward=6.22 +/- 7.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=109500, episode_reward=19.71 +/- 3.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 19.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -4.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 1427     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total timesteps  | 109900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.81     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=23.52 +/- 4.25\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=110500, episode_reward=21.24 +/- 7.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -3.61    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 1423     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total timesteps  | 110900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 15224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=111000, episode_reward=19.87 +/- 7.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=111500, episode_reward=23.15 +/- 2.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -3.27    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 1420     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total timesteps  | 111900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.474    |\n",
      "|    n_updates        | 15474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=112000, episode_reward=-8.09 +/- 6.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=112500, episode_reward=13.11 +/- 6.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 13.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -2.76    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 1417     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total timesteps  | 112900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.811    |\n",
      "|    n_updates        | 15724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=113000, episode_reward=18.38 +/- 5.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=113500, episode_reward=23.13 +/- 3.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -2.05    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 1414     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total timesteps  | 113900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 15974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=114000, episode_reward=16.84 +/- 5.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=114500, episode_reward=26.42 +/- 2.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -1.51    |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 1411     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total timesteps  | 114900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=18.54 +/- 5.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=115500, episode_reward=12.63 +/- 10.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 12.6     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -0.513   |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 1407     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total timesteps  | 115900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 16474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=116000, episode_reward=16.18 +/- 21.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=116500, episode_reward=21.51 +/- 2.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 1.87     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 1404     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total timesteps  | 116900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.728    |\n",
      "|    n_updates        | 16724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=117000, episode_reward=23.66 +/- 5.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=117500, episode_reward=17.98 +/- 4.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 18       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 3.27     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 1401     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total timesteps  | 117900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 16974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=118000, episode_reward=23.73 +/- 1.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=118500, episode_reward=28.07 +/- 4.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 28.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 1397     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total timesteps  | 118900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.94     |\n",
      "|    n_updates        | 17224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=119000, episode_reward=26.87 +/- 6.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=119500, episode_reward=19.21 +/- 6.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 19.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 1394     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total timesteps  | 119900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.622    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=15.40 +/- 4.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=120500, episode_reward=20.71 +/- 3.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 1391     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total timesteps  | 120900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.761    |\n",
      "|    n_updates        | 17724    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=121000, episode_reward=19.28 +/- 3.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=121500, episode_reward=13.26 +/- 11.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 13.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 1388     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total timesteps  | 121900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.674    |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=122000, episode_reward=25.53 +/- 4.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=122500, episode_reward=22.55 +/- 3.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 22.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 1385     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total timesteps  | 122900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.48     |\n",
      "|    n_updates        | 18224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=123000, episode_reward=10.63 +/- 18.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=123500, episode_reward=21.35 +/- 10.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 1381     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total timesteps  | 123900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 18474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=124000, episode_reward=23.60 +/- 2.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=124500, episode_reward=25.33 +/- 4.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 1379     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total timesteps  | 124900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.433    |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=26.46 +/- 2.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=125500, episode_reward=-25.33 +/- 8.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -25.3    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 1376     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total timesteps  | 125900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.767    |\n",
      "|    n_updates        | 18974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=126000, episode_reward=-12.43 +/- 7.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=126500, episode_reward=25.03 +/- 3.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 1372     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total timesteps  | 126900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 19224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=127000, episode_reward=25.91 +/- 3.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=127500, episode_reward=20.04 +/- 4.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 1370     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total timesteps  | 127900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 19474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=20.09 +/- 8.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=128500, episode_reward=26.57 +/- 1.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.6     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 1367     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total timesteps  | 128900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 19724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=129000, episode_reward=25.50 +/- 5.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=129500, episode_reward=22.67 +/- 4.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 22.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 1365     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total timesteps  | 129900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.805    |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=28.49 +/- 0.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=130500, episode_reward=25.79 +/- 3.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.8     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.5     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 1363     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total timesteps  | 130900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.549    |\n",
      "|    n_updates        | 20224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=131000, episode_reward=13.22 +/- 5.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=131500, episode_reward=23.37 +/- 3.99\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 1360     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total timesteps  | 131900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 20474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=132000, episode_reward=22.17 +/- 4.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=132500, episode_reward=-11.80 +/- 8.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -11.8    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 1357     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total timesteps  | 132900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.6      |\n",
      "|    n_updates        | 20724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=133000, episode_reward=-6.22 +/- 8.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=133500, episode_reward=12.71 +/- 9.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 12.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 1354     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total timesteps  | 133900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=134000, episode_reward=-1.32 +/- 6.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=134500, episode_reward=17.12 +/- 3.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 17.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16       |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 1352     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total timesteps  | 134900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=18.10 +/- 3.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=135500, episode_reward=25.22 +/- 3.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 1350     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total timesteps  | 135900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.915    |\n",
      "|    n_updates        | 21474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=136000, episode_reward=25.84 +/- 3.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=136500, episode_reward=18.29 +/- 4.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 18.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 1348     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total timesteps  | 136900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.66     |\n",
      "|    n_updates        | 21724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=137000, episode_reward=14.31 +/- 4.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=137500, episode_reward=21.69 +/- 2.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 1346     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total timesteps  | 137900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 21974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=138000, episode_reward=19.33 +/- 13.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=138500, episode_reward=23.87 +/- 2.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 1344     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total timesteps  | 138900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 22224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=139000, episode_reward=24.13 +/- 3.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=139500, episode_reward=25.32 +/- 4.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 1342     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total timesteps  | 139900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=25.40 +/- 2.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=140500, episode_reward=24.45 +/- 6.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.2     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 1339     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total timesteps  | 140900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.496    |\n",
      "|    n_updates        | 22724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=141000, episode_reward=22.97 +/- 3.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=141500, episode_reward=20.80 +/- 1.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20.8     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 1337     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total timesteps  | 141900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.615    |\n",
      "|    n_updates        | 22974    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=142000, episode_reward=18.80 +/- 3.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=142500, episode_reward=21.50 +/- 3.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 1334     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total timesteps  | 142900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 23224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=143000, episode_reward=27.69 +/- 3.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=143500, episode_reward=23.49 +/- 2.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 1332     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total timesteps  | 143900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.986    |\n",
      "|    n_updates        | 23474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=144000, episode_reward=23.88 +/- 4.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=144500, episode_reward=23.95 +/- 3.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 1330     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total timesteps  | 144900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.532    |\n",
      "|    n_updates        | 23724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=26.41 +/- 2.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=145500, episode_reward=25.45 +/- 2.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 1328     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total timesteps  | 145900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.771    |\n",
      "|    n_updates        | 23974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=146000, episode_reward=18.87 +/- 2.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=146500, episode_reward=21.11 +/- 2.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 1327     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total timesteps  | 146900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 24224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=147000, episode_reward=25.42 +/- 1.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=147500, episode_reward=23.70 +/- 3.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 1325     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total timesteps  | 147900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.394    |\n",
      "|    n_updates        | 24474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=148000, episode_reward=23.65 +/- 3.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=148500, episode_reward=26.60 +/- 2.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.6     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 1323     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total timesteps  | 148900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.781    |\n",
      "|    n_updates        | 24724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=149000, episode_reward=23.42 +/- 3.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=149500, episode_reward=23.96 +/- 2.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 1322     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total timesteps  | 149900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 24974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=24.61 +/- 4.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=150500, episode_reward=25.38 +/- 3.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 1321     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total timesteps  | 150900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.465    |\n",
      "|    n_updates        | 25224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=151000, episode_reward=23.41 +/- 3.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=151500, episode_reward=9.02 +/- 3.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 9.02     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 1319     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total timesteps  | 151900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.561    |\n",
      "|    n_updates        | 25474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=152000, episode_reward=22.87 +/- 2.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=152500, episode_reward=27.90 +/- 3.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 27.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 1318     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total timesteps  | 152900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 25724    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=153000, episode_reward=18.66 +/- 6.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=153500, episode_reward=24.02 +/- 2.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 1317     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total timesteps  | 153900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.861    |\n",
      "|    n_updates        | 25974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=154000, episode_reward=22.45 +/- 5.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=154500, episode_reward=20.53 +/- 2.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 1315     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total timesteps  | 154900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.272    |\n",
      "|    n_updates        | 26224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=17.65 +/- 5.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=155500, episode_reward=21.78 +/- 6.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 21.8     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 1314     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total timesteps  | 155900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 26474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=156000, episode_reward=25.12 +/- 1.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=156500, episode_reward=8.51 +/- 10.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 8.51     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 1313     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total timesteps  | 156900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.238    |\n",
      "|    n_updates        | 26724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=157000, episode_reward=3.82 +/- 12.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=157500, episode_reward=8.34 +/- 12.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 8.34     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 1312     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total timesteps  | 157900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.399    |\n",
      "|    n_updates        | 26974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=158000, episode_reward=29.07 +/- 5.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=158500, episode_reward=-7.20 +/- 8.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -7.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 1311     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total timesteps  | 158900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.799    |\n",
      "|    n_updates        | 27224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=159000, episode_reward=20.82 +/- 2.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=159500, episode_reward=23.46 +/- 2.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 1310     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total timesteps  | 159900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.373    |\n",
      "|    n_updates        | 27474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=17.54 +/- 9.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=160500, episode_reward=24.71 +/- 3.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 1309     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total timesteps  | 160900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.868    |\n",
      "|    n_updates        | 27724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=161000, episode_reward=31.40 +/- 3.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=161500, episode_reward=24.29 +/- 2.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 1308     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total timesteps  | 161900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 27974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=162000, episode_reward=26.65 +/- 5.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=162500, episode_reward=26.27 +/- 2.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 1307     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total timesteps  | 162900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.606    |\n",
      "|    n_updates        | 28224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=163000, episode_reward=15.10 +/- 4.74\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=163500, episode_reward=24.15 +/- 3.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 18.1     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 1306     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total timesteps  | 163900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.701    |\n",
      "|    n_updates        | 28474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=164000, episode_reward=21.17 +/- 4.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=164500, episode_reward=19.31 +/- 7.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 19.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 18.1     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 1304     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total timesteps  | 164900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 28724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=22.43 +/- 4.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=165500, episode_reward=26.09 +/- 1.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 1303     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total timesteps  | 165900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 28974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=166000, episode_reward=23.40 +/- 5.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=166500, episode_reward=23.29 +/- 1.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 1302     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total timesteps  | 166900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.67     |\n",
      "|    n_updates        | 29224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=167000, episode_reward=7.18 +/- 8.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=167500, episode_reward=26.12 +/- 3.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 1300     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total timesteps  | 167900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 29474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=168000, episode_reward=11.90 +/- 10.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=168500, episode_reward=20.00 +/- 6.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 1299     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total timesteps  | 168900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.312    |\n",
      "|    n_updates        | 29724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=169000, episode_reward=10.51 +/- 10.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=169500, episode_reward=15.80 +/- 4.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.8     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 1298     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total timesteps  | 169900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.617    |\n",
      "|    n_updates        | 29974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=26.96 +/- 2.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=170500, episode_reward=27.03 +/- 3.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 27       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 17       |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 1296     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total timesteps  | 170900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36     |\n",
      "|    n_updates        | 30224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=171000, episode_reward=29.71 +/- 2.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=171500, episode_reward=26.99 +/- 2.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 27       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 1295     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total timesteps  | 171900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 30474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=172000, episode_reward=23.79 +/- 6.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=172500, episode_reward=10.69 +/- 6.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 10.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 1294     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total timesteps  | 172900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 30724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=173000, episode_reward=18.73 +/- 6.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=173500, episode_reward=-1.20 +/- 14.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -1.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 1294     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total timesteps  | 173900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 30974    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=174000, episode_reward=17.87 +/- 10.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=174500, episode_reward=27.23 +/- 7.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 27.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 1293     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total timesteps  | 174900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.614    |\n",
      "|    n_updates        | 31224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=28.07 +/- 5.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=175500, episode_reward=2.10 +/- 15.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 2.1      |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 1292     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total timesteps  | 175900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 31474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=176000, episode_reward=12.37 +/- 11.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=176500, episode_reward=22.01 +/- 4.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 22       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 1292     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total timesteps  | 176900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.567    |\n",
      "|    n_updates        | 31724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=177000, episode_reward=14.35 +/- 7.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=177500, episode_reward=-4.74 +/- 9.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -4.74    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 1291     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total timesteps  | 177900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 31974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=178000, episode_reward=27.97 +/- 3.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=178500, episode_reward=22.99 +/- 2.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 1290     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total timesteps  | 178900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.869    |\n",
      "|    n_updates        | 32224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=179000, episode_reward=27.05 +/- 2.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=179500, episode_reward=26.21 +/- 0.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 26.2     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 1289     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total timesteps  | 179900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.322    |\n",
      "|    n_updates        | 32474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=20.66 +/- 6.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=180500, episode_reward=7.24 +/- 5.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 7.24     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 1288     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total timesteps  | 180900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.504    |\n",
      "|    n_updates        | 32724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=181000, episode_reward=12.75 +/- 9.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=181500, episode_reward=18.81 +/- 6.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 18.8     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 1287     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total timesteps  | 181900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.308    |\n",
      "|    n_updates        | 32974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=182000, episode_reward=-7.83 +/- 8.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=182500, episode_reward=15.92 +/- 10.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 15.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 1285     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total timesteps  | 182900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 33224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=183000, episode_reward=6.09 +/- 8.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=183500, episode_reward=25.34 +/- 4.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 1284     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total timesteps  | 183900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.473    |\n",
      "|    n_updates        | 33474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=184000, episode_reward=24.82 +/- 4.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=184500, episode_reward=24.46 +/- 3.34\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 1283     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total timesteps  | 184900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 33724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=27.27 +/- 4.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=185500, episode_reward=25.08 +/- 2.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.1     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 1282     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total timesteps  | 185900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 33974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=186000, episode_reward=24.74 +/- 2.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=186500, episode_reward=25.29 +/- 3.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 1281     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total timesteps  | 186900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.489    |\n",
      "|    n_updates        | 34224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=187000, episode_reward=27.76 +/- 3.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=187500, episode_reward=29.78 +/- 4.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 29.8     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 1281     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total timesteps  | 187900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 34474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=188000, episode_reward=23.70 +/- 4.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=188500, episode_reward=10.88 +/- 7.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 10.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 1280     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total timesteps  | 188900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.287    |\n",
      "|    n_updates        | 34724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=189000, episode_reward=9.68 +/- 4.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=189500, episode_reward=19.28 +/- 12.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 19.3     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 16       |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 1280     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total timesteps  | 189900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 34974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=190000, episode_reward=22.88 +/- 1.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=190500, episode_reward=4.28 +/- 9.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 4.28     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 1280     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total timesteps  | 190900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 35224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=191000, episode_reward=25.87 +/- 3.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=191500, episode_reward=28.86 +/- 3.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 28.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 1279     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total timesteps  | 191900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.75     |\n",
      "|    n_updates        | 35474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=-9.12 +/- 9.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=192500, episode_reward=24.40 +/- 2.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 24.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 1278     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total timesteps  | 192900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 35724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=193000, episode_reward=21.47 +/- 1.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=193500, episode_reward=22.95 +/- 3.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 23       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 1277     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total timesteps  | 193900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 35974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=194000, episode_reward=-0.62 +/- 17.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=194500, episode_reward=20.49 +/- 7.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 20.5     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 1276     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total timesteps  | 194900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 36224    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=195000, episode_reward=28.60 +/- 4.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=195500, episode_reward=29.92 +/- 6.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 29.9     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 1274     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total timesteps  | 195900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.422    |\n",
      "|    n_updates        | 36474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=196000, episode_reward=26.85 +/- 5.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=196500, episode_reward=17.71 +/- 6.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 17.7     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 1273     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total timesteps  | 196900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.356    |\n",
      "|    n_updates        | 36724    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=197000, episode_reward=29.71 +/- 4.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=197500, episode_reward=8.52 +/- 4.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 8.52     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 1272     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total timesteps  | 197900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.515    |\n",
      "|    n_updates        | 36974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=198000, episode_reward=16.72 +/- 8.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=198500, episode_reward=25.41 +/- 3.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | 25.4     |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 1271     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total timesteps  | 198900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.574    |\n",
      "|    n_updates        | 37224    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=199000, episode_reward=20.30 +/- 9.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=199500, episode_reward=-4.45 +/- 7.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 200      |\n",
      "|    mean_reward      | -4.45    |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 1269     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total timesteps  | 199900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 37474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=10.49 +/- 14.18\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x16462c61430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
    "                             log_path='./logs/', eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "\n",
    "print(\"Model not found! Starting training...\")\n",
    "policy_kwargs = dict(net_arch=[10,10])\n",
    "model = DQN('MlpPolicy', env, policy_kwargs=policy_kwargs, verbose=1, gamma=1.0, tensorboard_log=\"./logs/\")\n",
    "total_timesteps = 200000\n",
    "model.learn(total_timesteps=total_timesteps,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, DQN, A2C\n",
    "\n",
    "# Load best model!\n",
    "model = DQN.load(\"./logs/best_model.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-PRu_fXD0ENx"
   },
   "outputs": [],
   "source": [
    "# optimal policy agent as per Avellaneda\n",
    "\n",
    "def spread_func(beta, sigma, k):\n",
    "    return lambda T_t: spread(beta, sigma, T_t, k) \n",
    "\n",
    "def r_func(sigma, beta):\n",
    "    return lambda T_t, s, q: r(beta, sigma, T_t, s, q)\n",
    "    \n",
    "class AvellanedaAgent:\n",
    "    def __init__(self, beta, sigma, k):\n",
    "        self.spread_func = spread_func(beta, sigma, k)\n",
    "        self.r_func = r_func(sigma, beta)\n",
    "        \n",
    "    def act(self, observation):\n",
    "        spread = self.spread_func(observation[2])\n",
    "        r_ = self.r_func(observation[2], observation[0], observation[1])\n",
    "        \n",
    "        bid = r_ - spread/2\n",
    "        ask = r_ + spread/2\n",
    "\n",
    "        ds = observation[0] - r_\n",
    "        \n",
    "        #return spread, ds\n",
    "        return ds\n",
    "\n",
    "    def step(self,observation):\n",
    "        return self.act(observation)\n",
    "\n",
    "#agent = AvellanedaAgent(gamma, sigma, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S7FXF8L50K2V"
   },
   "outputs": [],
   "source": [
    "# symmetrical policy agent as per Avellaneda\n",
    "\n",
    "class SymmetricAgent:\n",
    "    def __init__(self, beta, sigma, k):\n",
    "        self.spread_func = spread_func(beta, sigma, k)\n",
    "        \n",
    "    def act(self, observation):\n",
    "        #spread = self.spread_func(observation[2])\n",
    "        return 0\n",
    "\n",
    "    def step(self,observation):\n",
    "        return self.act(observation)\n",
    "\n",
    "#symmetric_agent = SymmetricAgent(gamma, sigma, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_GGrBbZWz7pK"
   },
   "outputs": [],
   "source": [
    "def run_env_agent_comp(envs, agent_rl,agent_opt,agent_sym):\n",
    "    \n",
    "    env = envs[0]\n",
    "    \n",
    "    obs = env.reset()\n",
    "    bids_rl = np.zeros(env.n)\n",
    "    asks_rl = np.zeros(env.n)\n",
    "    ss_rl = np.zeros(env.n)\n",
    "    ws_rl = np.zeros(env.n)\n",
    "    qs_rl = np.zeros(env.n)\n",
    "    final = False\n",
    "    i = 0\n",
    "\n",
    "    total_reward_rl = 0.0\n",
    "    while not final:\n",
    "\n",
    "        #action_rl = agent_rl.predict(obs,deterministic=True)\n",
    "        action_rl = agent_rl.predict(obs,deterministic=True)\n",
    "        ss_rl[i] = obs[0]\n",
    "        qs_rl[i] = obs[1]\n",
    "        \n",
    "        despl = (action_rl[0]-(actions_num-1)/2)*max_abs_dif/(actions_num-1)\n",
    "        ba_spread = spread(env.beta,env.sigma,env.T-env.t,env.k)\n",
    "\n",
    "        bids_rl[i] = ss_rl[i] - despl - ba_spread/2\n",
    "        asks_rl[i] = ss_rl[i] - despl + ba_spread/2\n",
    "\n",
    "        obs, reward, final, w_rl = env.step(action_rl[0])\n",
    "        i += 1\n",
    "        total_reward_rl += reward\n",
    "\n",
    "      \n",
    "    \n",
    "\n",
    "    env = envs[1]\n",
    "    \n",
    "    obs = env.reset()\n",
    "    bids_opt = np.zeros(env.n)\n",
    "    asks_opt = np.zeros(env.n)\n",
    "    ds_opt = np.zeros(env.n)\n",
    "    spread_opt = np.zeros(env.n)\n",
    "    ss_opt = np.zeros(env.n)\n",
    "    ws_opt = np.zeros(env.n)\n",
    "    qs_opt = np.zeros(env.n)\n",
    "    final = False\n",
    "    i = 0\n",
    "\n",
    "    total_reward_opt = 0.0\n",
    "    while not final:\n",
    "        action_opt = agent_opt.step(obs)\n",
    "\n",
    "        ds_opt[i] = action_opt\n",
    "        spread_opt[i] = spread(env.beta,env.sigma,env.T-env.t,env.k)\n",
    "        \n",
    "        ss_opt[i] = obs[0]\n",
    "        qs_opt[i] = obs[1]\n",
    "\n",
    "        bids_opt[i] = ss_opt[i] - ds_opt[i] - spread_opt[i]/2\n",
    "        asks_opt[i] = ss_opt[i] - ds_opt[i] + spread_opt[i]/2\n",
    "\n",
    "        obs, reward, final, w_opt = env.step(action_opt)\n",
    "        total_reward_opt += reward\n",
    "        i += 1\n",
    "\n",
    "    env = envs[2]\n",
    "\n",
    "    obs = env.reset()\n",
    "    bids_sym = np.zeros(env.n)\n",
    "    asks_sym = np.zeros(env.n)\n",
    "    ds_sym = np.zeros(env.n)\n",
    "    spread_sym = np.zeros(env.n)\n",
    "    ss_sym = np.zeros(env.n)\n",
    "    ws_sym = np.zeros(env.n)\n",
    "    qs_sym = np.zeros(env.n)    \n",
    "    final = False\n",
    "    i = 0\n",
    "\n",
    "    total_reward_sym = 0.0\n",
    "    while not final:\n",
    "        action_sym = agent_sym.step(obs)\n",
    "\n",
    "        ds_sym[i] = action_sym\n",
    "        spread_sym[i] = spread(env.beta,env.sigma,env.T-env.t,env.k)\n",
    "        \n",
    "        ss_sym[i] = obs[0]\n",
    "        qs_sym[i] = obs[1]\n",
    "\n",
    "        bids_sym[i] = ss_sym[i] - ds_sym[i] - spread_sym[i]/2\n",
    "        asks_sym[i] = ss_sym[i] - ds_sym[i] + spread_sym[i]/2\n",
    "        \n",
    "        obs, reward, final, w_sym = env.step(action_sym)\n",
    "        i += 1\n",
    "        total_reward_sym += reward\n",
    "\n",
    "        \n",
    "    return w_rl['w'], w_opt['w'], w_sym['w'],total_reward_rl,total_reward_opt,total_reward_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pgV6nOhgAupx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "1.0%\n",
      "2.0%\n",
      "3.0%\n",
      "4.0%\n",
      "5.0%\n",
      "6.0%\n",
      "7.0%\n",
      "8.0%\n",
      "9.0%\n",
      "10.0%\n",
      "11.0%\n",
      "12.0%\n",
      "13.0%\n",
      "14.0%\n",
      "15.0%\n",
      "16.0%\n",
      "17.0%\n",
      "18.0%\n",
      "19.0%\n",
      "20.0%\n",
      "21.0%\n",
      "22.0%\n",
      "23.0%\n",
      "24.0%\n",
      "25.0%\n",
      "26.0%\n",
      "27.0%\n",
      "28.0%\n",
      "29.0%\n",
      "30.0%\n",
      "31.0%\n",
      "32.0%\n",
      "33.0%\n",
      "34.0%\n",
      "35.0%\n",
      "36.0%\n",
      "37.0%\n",
      "38.0%\n",
      "39.0%\n",
      "40.0%\n",
      "41.0%\n",
      "42.0%\n",
      "43.0%\n",
      "44.0%\n",
      "45.0%\n",
      "46.0%\n",
      "47.0%\n",
      "48.0%\n",
      "49.0%\n",
      "50.0%\n",
      "51.0%\n",
      "52.0%\n",
      "53.0%\n",
      "54.0%\n",
      "55.0%\n",
      "56.0%\n",
      "57.0%\n",
      "58.0%\n",
      "59.0%\n",
      "60.0%\n",
      "61.0%\n",
      "62.0%\n",
      "63.0%\n",
      "64.0%\n",
      "65.0%\n",
      "66.0%\n",
      "67.0%\n",
      "68.0%\n",
      "69.0%\n",
      "70.0%\n",
      "71.0%\n",
      "72.0%\n",
      "73.0%\n",
      "74.0%\n",
      "75.0%\n",
      "76.0%\n",
      "77.0%\n",
      "78.0%\n",
      "79.0%\n",
      "80.0%\n",
      "81.0%\n",
      "82.0%\n",
      "83.0%\n",
      "84.0%\n",
      "85.0%\n",
      "86.0%\n",
      "87.0%\n",
      "88.0%\n",
      "89.0%\n",
      "90.0%\n",
      "91.0%\n",
      "92.0%\n",
      "93.0%\n",
      "94.0%\n",
      "95.0%\n",
      "96.0%\n",
      "97.0%\n",
      "98.0%\n",
      "99.0%\n"
     ]
    }
   ],
   "source": [
    "number_of_sims = 1000\n",
    "\n",
    "n = int(T/dt)\n",
    "ws_rl = np.zeros(number_of_sims)\n",
    "ws_opt = np.zeros(number_of_sims)\n",
    "ws_sym = np.zeros(number_of_sims)\n",
    "tr_rl = np.zeros(number_of_sims)\n",
    "tr_opt = np.zeros(number_of_sims)\n",
    "tr_sym = np.zeros(number_of_sims)\n",
    "\n",
    "envs = [AvellanedaEnv(s0, T, dt, sigma, beta, k, A, kappa),AvellanedaEnv(s0, T, dt, sigma, beta, k, A,kappa, seed=0, is_discrete=False),AvellanedaEnv(s0, T, dt, sigma, beta, k, A,kappa, seed=0, is_discrete=False)]\n",
    "for i in range(number_of_sims):\n",
    "    if i%10 == 0:\n",
    "        print(str(i/10) + \"%\")\n",
    "    ws_rl[i], ws_opt[i], ws_sym[i], tr_rl[i], tr_opt[i], tr_sym[i] = run_env_agent_comp(envs, model,AvellanedaAgent(beta, sigma, k),SymmetricAgent(beta, sigma, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Byg9c4wIC22a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accumulated wealth histogram')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure 2 (p. 222)\n",
    "'''\n",
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([ws_opt,ws_sym,ws_rl], bins=30,edgecolor='black', label=['Optimum', 'Symmetric','RL Discrete'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Wealth\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")\n",
    "'''\n",
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([ws_opt,ws_rl], bins=30,edgecolor='black', label=['Optimum','RL Discrete'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Wealth\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5QZDlL5dN3DX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accumulated wealth histogram')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABlkAAAKxCAYAAADQNsoqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/VUlEQVR4nOzdeZxWdd0//tcMDDCAgOyggLiDu3anuK+QormQu7mmZWoqZel9u+BK2a2Z5lLdhpigpak/MzdcsdwtzdRM0xxTFlERZR2Y6/dHN9e3uQG9PAzMIM/n48FDrs/5nM95n3PNOx/Ny3NOValUKgUAAAAAAIDPpLq5CwAAAAAAAFgRCVkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAACAxdpxxx2z4447NncZjVx33XWpqqrKP/7xj+YupSKjRo1KVVXVZ5o7bdq0Qsfacccds+GGG37qvH/84x+pqqrKddddV+g4AADA/yNkAQCAJbjqqqtSVVWVLbfcsrlLWaHMmjUro0aNysMPP9zcpbRIF110UW6//fbmLuMzu+qqqwQzAADwfwhZAABgCcaNG5c11lgjTz31VF577bXmLmeFMWvWrJx77rlCliVo7pBlwIABmT17dr761a9+pv2ELAAAsCghCwAALMYbb7yRxx57LJdeeml69OiRcePGNXdJ0CSqqqrSrl27tGrVqrlL+UxmzZrV3CUAAMAihCwAALAY48aNy6qrrprhw4fnK1/5yhJDlunTp+fUU0/NGmuskbZt22b11VfP4Ycf3ui9GnPmzMmoUaOy7rrrpl27dunTp0/222+//P3vf0+SPPzww6mqqlrkzo/FvTvjyCOPTMeOHVNXV5c999wzHTt2zGqrrZYrr7wySfLCCy9k5513TocOHTJgwICMHz++0ZpLekdIJe86mTdvXs4+++xsscUW6dy5czp06JDtttsuDz30UKOae/TokSQ599xzU1VVlaqqqowaNao8569//Wu+8pWvpGvXrmnXrl2+8IUv5I477ljkeC+++GJ23nnn1NbWZvXVV88FF1yQhoaGJda30B133JGqqqr8+c9/Lo/95je/SVVVVfbbb79GcwcNGpQDDzyw0dgNN9yQLbbYIrW1tenatWsOOuigvPXWW43mPProo9l///3Tv3//tG3bNv369cupp56a2bNnf2JtVVVVmTlzZsaOHVu+NkceeWSjOdOnT8+RRx6ZLl26pHPnzjnqqKM+U8Dw0ksvZaeddkr79u2z2mqr5eKLL260fXE/V5MnT85RRx2V1VdfPW3btk2fPn2y9957l38e1lhjjbz44ot55JFHynX/+/t6Xn/99ey///7p2rVr2rdvn6222iq/+93vFqntzTffzJe//OV06NAhPXv2zKmnnpp77713kZ//he+XefbZZ7P99tunffv2+c///M8kyf/3//1/GT58ePr27Zu2bdtmrbXWyvnnn58FCxY0OtbCNf785z9nhx12SPv27bP22mvnlltuSZI88sgj2XLLLVNbW5v11lsv999/f8XXGAAAFmrd3AUAAEBLNG7cuOy3335p06ZNDj744Fx99dV5+umn8x//8R/lOR9//HG22267vPzyyzn66KOz+eabZ9q0abnjjjvyz3/+M927d8+CBQuy55575oEHHshBBx2Uk08+OR999FEmTJiQv/zlL1lrrbU+c20LFizI7rvvnu233z4XX3xxxo0blxNPPDEdOnTIf/3Xf+XQQw/Nfvvtl2uuuSaHH354hgwZkoEDBy71NZkxY0b+53/+JwcffHCOPfbYfPTRR7n22mszbNiwPPXUU9l0003To0ePXH311Tn++OOz7777lkONjTfeOMm/gpNtttkmq622Wk4//fR06NAhv/71r7PPPvvkN7/5Tfbdd98k//ql/0477ZT58+eX5/3sZz9LbW3tp9a57bbbpqqqKhMnTiwf99FHH011dXV+//vfl+e9++67+etf/5oTTzyxPHbhhRfmrLPOygEHHJCvfe1reffdd3PFFVdk++23z5/+9Kd06dIlSXLzzTdn1qxZOf7449OtW7c89dRTueKKK/LPf/4zN9988xJr++Uvf5mvfe1r+eIXv5jjjjsuSRb5GTjggAMycODAjB49On/84x/zP//zP+nZs2d+8IMffOq5f/DBB/nSl76U/fbbLwcccEBuueWWfO9738tGG22U3XfffYn7jRgxIi+++GJOOumkrLHGGpk6dWomTJiQurq6rLHGGrnsssty0kknpWPHjvmv//qvJEmvXr2SJFOmTMnWW2+dWbNm5Vvf+la6deuWsWPH5stf/nJuueWW8nc6c+bM7Lzzzpk0aVJOPvnk9O7dO+PHj28U0v279957L7vvvnsOOuigHHbYYeXjXXfddenYsWNGjhyZjh075sEHH8zZZ5+dGTNm5Ic//OEi12PPPffMQQcdlP333z9XX311DjrooIwbNy6nnHJKvvGNb+SQQw7JD3/4w3zlK1/JW2+9lVVWWeVTrzMAAJSVAACARp555plSktKECRNKpVKp1NDQUFp99dVLJ598cqN5Z599dilJ6dZbb11kjYaGhlKpVCr94he/KCUpXXrppUuc89BDD5WSlB566KFG2994441SktKYMWPKY0cccUQpSemiiy4qj33wwQel2traUlVVVemmm24qj//1r38tJSmdc8455bFzzjmntLj/GzBmzJhSktIbb7xRHtthhx1KO+ywQ/nz/PnzS3Pnzm203wcffFDq1atX6eijjy6Pvfvuu4scd6FddtmltNFGG5XmzJnT6DpsvfXWpXXWWac8dsopp5SSlJ588sny2NSpU0udO3depM7F2WCDDUoHHHBA+fPmm29e2n///UtJSi+//HKpVCqVbr311lKS0vPPP18qlUqlf/zjH6VWrVqVLrzwwkZrvfDCC6XWrVs3Gp81a9Yixxw9enSpqqqq9Oabb5bHFne9O3ToUDriiCMW2X/h3H+/lqVSqbTvvvuWunXr9onnWyr96/tKUrr++uvLY3Pnzi317t27NGLEiPLY//25+uCDD0pJSj/84Q8/cf0NNtig0c/DQgu/q0cffbQ89tFHH5UGDhxYWmONNUoLFiwolUql0iWXXFJKUrr99tvL82bPnl1af/31F/n5X3gu11xzzSLHW9y1//rXv15q3759o5+rhWuMHz++PLawJ6qrq0tPPPFEefzee+9dpNcAAKASHhcGAAD/x7hx49KrV6/stNNOSf71iKcDDzwwN910U6NHEv3mN7/JJptsUv4v9f/dwkdy/eY3v0n37t1z0kknLXFOEV/72tfKf+/SpUvWW2+9dOjQIQcccEB5fL311kuXLl3y+uuvFz7Ov2vVqlXatGmTJGloaMj777+f+fPn5wtf+EL++Mc/fur+77//fh588MEccMAB+eijjzJt2rRMmzYt7733XoYNG5ZXX301b7/9dpLkrrvuylZbbZUvfvGL5f179OiRQw89tKJat9tuuzz66KNJko8++ijPP/98jjvuuHTv3r08/uijj6ZLly7ZcMMNkyS33nprGhoacsABB5RrmzZtWnr37p111lmn0R0X/35HzcyZMzNt2rRsvfXWKZVK+dOf/lRRjUvyjW98Y5Fzee+99zJjxoxP3bdjx4457LDDyp/btGmTL37xi5/4M1BbW5s2bdrk4YcfzgcffPCZ673rrrvyxS9+Mdtuu22jOo477rj84x//yEsvvZQkueeee7Laaqvly1/+cnleu3btcuyxxy523bZt2+aoo45abL0LLfw52m677TJr1qz89a9/bTS3Y8eOOeigg8qfF/bEoEGDsuWWW5bHF/69qXoFAICVh5AFAAD+zYIFC3LTTTdlp512yhtvvJHXXnstr732WrbccstMmTIlDzzwQHnu3//+9/Iv6Jfk73//e9Zbb720bt10T+pt165d+b0nC3Xu3Dmrr776IsFN586dC/3ifEnGjh2bjTfeOO3atUu3bt3So0eP/O53v8uHH374qfu+9tprKZVKOeuss9KjR49Gf84555wkydSpU5P8690d66yzziJrrLfeehXVud1222XSpEl57bXX8thjj6WqqipDhgxpFL48+uij2WabbVJd/a//W/Tqq6+mVCplnXXWWaS+l19+uVxbktTV1eXII49M165d07Fjx/To0SM77LBDklR0LT5J//79G31eddVVk6Si73FxPwOrrrrqJ+7btm3b/OAHP8jdd9+dXr16lR9DN3ny5IrqffPNNxf7vQwaNKi8feE/11prrUXqW3vttRe77mqrrVYO9f7diy++mH333TedO3dOp06d0qNHj3Kw9H+v/ZJ6ol+/fouMJZVdYwAA+HfeyQIAAP/mwQcfzKRJk3LTTTflpptuWmT7uHHjMnTo0CY95pLuaPm/L/JeqFWrVp9pvFQqFT7Wv7vhhhty5JFHZp999slpp52Wnj17plWrVhk9enT+/ve/f+r+C19a/53vfCfDhg1b7Jwl/cL9s1p4V8XEiRPz+uuvZ/PNN0+HDh2y3Xbb5fLLL8/HH3+cP/3pT7nwwgsb1VdVVZW77757sdeyY8eOSf51rXbbbbe8//77+d73vpf1118/HTp0yNtvv50jjzyyfJ5FVfI9NvW+p5xySvbaa6/cfvvtuffee3PWWWdl9OjRefDBB7PZZpt9etHLwOLevzN9+vTssMMO6dSpU84777ystdZaadeuXf74xz/me9/73iLXfml6BQAAKiFkAQCAfzNu3Lj07NkzV1555SLbbr311tx222255pprUltbm7XWWit/+ctfPnG9tdZaK08++WTq6+tTU1Oz2DkL71SYPn16o/GFdwA0pX8/1sKXuFd6rFtuuSVrrrlmbr311kZhzcK7UBZaUpCz5pprJklqamqy6667fuKxBgwYkFdffXWR8VdeeeVT60z+dTdI//798+ijj+b111/PdtttlyTZfvvtM3LkyNx8881ZsGBBtt9++/I+a621VkqlUgYOHJh11113iWu/8MIL+dvf/paxY8fm8MMPL49PmDChotqW5jFxy9Jaa62Vb3/72/n2t7+dV199NZtuumkuueSS3HDDDUmWXPeAAQMW+70sfHTXgAEDyv986aWXUiqVGq312muvVVzjww8/nPfeey+33npro+/ujTfeqHgNAABoSh4XBgAA/2v27Nm59dZbs+eee+YrX/nKIn9OPPHEfPTRR7njjjuSJCNGjMjzzz+f2267bZG1Fv4X8SNGjMi0adPyk5/8ZIlzBgwYkFatWmXixImNtl911VVNfYpZa621kqTRsWbOnJmxY8d+6r4L/+v/f/+v/Z988sk8/vjjjea1b98+yaKhUc+ePbPjjjvmpz/9aSZNmrTI+u+++27573vssUeeeOKJPPXUU422jxs37lPrXGi77bbLgw8+mKeeeqocsmy66aZZZZVV8v3vfz+1tbXZYostyvP322+/tGrVKueee+4idzSUSqW89957S7wOpVIpP/7xjyuqq0OHDotcm+Y0a9aszJkzp9HYWmutlVVWWSVz584tjy2p7j322CNPPfVUo5+DmTNn5mc/+1nWWGONDB48OEkybNiwvP322+X+SZI5c+bk5z//ecW1Lu7az5s3b5n0CgAAVMKdLAAA8L/uuOOOfPTRR41ezP3vttpqq/To0SPjxo3LgQcemNNOOy233HJL9t9//xx99NHZYost8v777+eOO+7INddck0022SSHH354rr/++owcObL8y/6ZM2fm/vvvzze/+c3svffe6dy5c/bff/9cccUVqaqqylprrZU777yz0TtAmsrQoUPTv3//HHPMMTnttNPSqlWr/OIXv0iPHj1SV1f3ifvuueeeufXWW7Pvvvtm+PDheeONN3LNNddk8ODB+fjjj8vzamtrM3jw4PzqV7/Kuuuum65du2bDDTfMhhtumCuvvDLbbrttNtpooxx77LFZc801M2XKlDz++OP55z//meeffz5J8t3vfje//OUv86UvfSknn3xyOnTokJ/97GcZMGBA/vznP1d0rtttt13GjRuXqqqq8uPDWrVqla233jr33ntvdtxxx0bv/FhrrbVywQUX5Iwzzsg//vGP7LPPPllllVXyxhtv5Lbbbstxxx2X73znO1l//fWz1lpr5Tvf+U7efvvtdOrUKb/5zW8qfp/HFltskfvvvz+XXnpp+vbtm4EDBzZ6Cfvy9re//S277LJLDjjggAwePDitW7fObbfdlilTpjR6afwWW2yRq6++OhdccEHWXnvt9OzZMzvvvHNOP/303Hjjjdl9993zrW99K127ds3YsWPzxhtv5De/+U35nTdf//rX85Of/CQHH3xwTj755PTp0yfjxo1Lu3btklR2h8/WW2+dVVddNUcccUS+9a1vpaqqKr/85S895gsAgGYjZAEAgP+18Be+u+2222K3V1dXZ/jw4Rk3blzee++9dOvWLY8++mjOOeec3HbbbRk7dmx69uyZXXbZJauvvnqSf/1S/6677sqFF16Y8ePH5ze/+U26detWDhoWuuKKK1JfX59rrrkmbdu2zQEHHJAf/vCH2XDDDZv0HGtqanLbbbflm9/8Zs4666z07t07p5xySlZdddUcddRRn7jvkUcemcmTJ+enP/1p7r333gwePDg33HBDbr755jz88MON5v7P//xPTjrppJx66qmZN29ezjnnnGy44YYZPHhwnnnmmZx77rm57rrr8t5776Vnz57ZbLPNcvbZZ5f379OnTx566KGcdNJJ+f73v59u3brlG9/4Rvr27ZtjjjmmonNdePfK+uuvn27dujUav/fee8vb/93pp5+eddddNz/60Y9y7rnnJkn69euXoUOHlsO3mpqa/Pa3v823vvWtjB49Ou3atcu+++6bE088MZtsssmn1nXppZfmuOOOy5lnnpnZs2fniCOOaNaQpV+/fjn44IPzwAMP5Je//GVat26d9ddfP7/+9a8zYsSI8ryzzz47b775Zi6++OJ89NFH2WGHHbLzzjunV69eeeyxx/K9730vV1xxRebMmZONN944v/3tbzN8+PDy/h07dsyDDz6Yk046KT/+8Y/TsWPHHH744dl6660zYsSIctjySbp165Y777wz3/72t3PmmWdm1VVXzWGHHZZddtllie/5AQCAZamq5D/5AQAAoJlcdtllOfXUU/PPf/4zq622WnOXAwAAn4mQBQAAgOVi9uzZqa2tLX+eM2dONttssyxYsCB/+9vfmrEyAAAoxuPCAAAAWC7222+/9O/fP5tuumk+/PDD3HDDDfnrX/+acePGNXdpAABQiJAFAACA5WLYsGH5n//5n4wbNy4LFizI4MGDc9NNN+XAAw9s7tIAAKAQjwsDAAAAAAAooLq5CwAAAAAAAFgRCVkAAAAAAAAK8E6WJA0NDXnnnXeyyiqrpKqqqrnLAQAAAAAAmlGpVMpHH32Uvn37prp6yferCFmSvPPOO+nXr19zlwEAAAAAALQgb731VlZfffUlbheyJFlllVWS/OtiderUqZmr+fypr6/Pfffdl6FDh6ampqa5y4EWTb9A5fQLVEavQOX0C1RGr0Dl9AtUrqX1y4wZM9KvX79yfrAkQpak/IiwTp06CVmWgfr6+rRv3z6dOnVqEc0BLZl+gcrpF6iMXoHK6ReojF6ByukXqFxL7ZdPe8WIF98DAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgHeyAAAAAABAklKplPnz52fBggXNXcpKp76+Pq1bt86cOXOWy/Vv1apVWrdu/anvXPk0QhYAAAAAAFZ68+bNy6RJkzJr1qzmLmWlVCqV0rt377z11ltLHXxUqn379unTp0/atGlTeA0hCwAAAAAAK7WGhoa88cYbadWqVfr27Zs2bdost1/08y8NDQ35+OOP07Fjx1RXL9s3nZRKpcybNy/vvvtu3njjjayzzjqFjylkAQAAAABgpTZv3rw0NDSkX79+ad++fXOXs1JqaGjIvHnz0q5du2UesiRJbW1tampq8uabb5aPW4QX3wMAAAAAQLJcfrlPy9EU37efGAAAAAAAgAI8LgwAAAAAAJagrq4u06ZNW27H6969e/r377/cjsfSEbIAAAAAAMBi1NXVZb31B2XO7FnL7Zjtatvnlb++3KKCllGjRuX222/Pc88919yltDhCFgAAAAAAWIxp06ZlzuxZ6bbnt1PTrd8yP179e2/lvTsvybRp0z5zyPLWW2/lnHPOyT333JNp06alT58+2WeffXL22WenW7duFa9TVVWV2267Lfvss0957Dvf+U5OOumkz1TPykLIAgAAAAAAn6CmW7+07b12c5exRK+//nqGDBmSddddNzfeeGMGDhyYF198MaeddlruvvvuPPHEE+natWvh9Tt27JiOHTs2YcWfH158DwAAAAAAK7ATTjghbdq0yX333Zcddtgh/fv3z+677577778/b7/9dv7rv/4rSbLGGmvk/PPPz8EHH5wOHTpktdVWy5VXXlleZ4011kiS7Lvvvqmqqip/HjVqVDbddNPyvCOPPDL77LNPLrroovTq1StdunTJeeedl/nz5+e0005L165ds/rqq2fMmDHlfR5++OFUVVVl+vTp5bHnnnsuVVVV+cc//pEkGT9+fLp27Zo777wz6623Xtq3b5+vfOUrmTVrVsaOHZs11lgjq666ar71rW9lwYIFy+RaflZCFgAAAAAAWEG9//77uffee/PNb34ztbW1jbb17t07hx56aH71q1+lVColSX74wx9mk002yZ/+9KecfvrpOfnkkzNhwoQkydNPP50kGTNmTCZNmlT+vDgPPvhg3nnnnUycODGXXnppzjnnnOy5555ZddVV8+STT+Yb3/hGvv71r+ef//znZzqfWbNm5fLLL89NN92Ue+65Jw8//HD23Xff3HXXXbnrrrvyy1/+Mj/96U9zyy23fKZ1lxWPCwMAAAAAgBXUq6++mlKplEGDBi12+6BBg/LBBx/k3XffTZJss802Of3005Mk6667bv7whz/kRz/6UXbbbbf06NEjSdKlS5f07t37E4/btWvXXH755amurs56662Xiy++OLNmzcp//ud/JknOOOOMfP/738/vf//7HHTQQRWfT319fa6++uqstdZaSZKvfOUr+eUvf5kpU6akY8eOGTx4cHbaaac89NBDOfDAAyted1lxJwsAAAAAAKzgFt6p8mmGDBmyyOeXX375Mx9vgw02SHX1/4sYevXqlY022qj8uVWrVunWrVumTp36mdZt3759OWBZuO4aa6zR6J0wvXr1+szrLitCFgAAAAAAWEGtvfbaqaqqWmJQ8vLLL2fVVVct36XSVGpqahp9rqqqWuxYQ0NDkpQDmX8Pg+rr65d63eYmZAEAAAAAgBVUt27dsttuu+Wqq67K7NmzG22bPHlyxo0blwMPPDBVVVVJkieeeKLRnCeeeKLRo8ZqamqWyUvlF4Y8kyZNKo8999xzTX6c5c07WQAAAAAA4BPUv/dWiz7OT37yk2y99dYZNmxYLrjgggwcODAvvvhiTjvttKy22mq58MILy3P/8Ic/5OKLL84+++yTCRMm5Oabb87vfve78vY11lgjDzzwQLbZZpu0bds2q6666lKfV/KvO2769euXUaNG5cILL8zf/va3XHLJJU2ydnMSsgAAAAAAwGJ079497Wrb5707l18Y0K62fbp37/6Z9llnnXXyzDPP5JxzzskBBxyQ999/P717984+++yTc845J127di3P/fa3v51nnnkm5557bjp16pRLL700w4YNK2+/5JJLMnLkyPz85z/Paqutln/84x9Ncl41NTW58cYbc/zxx2fjjTfOf/zHf+SCCy7I/vvv3yTrNxchCwAAAAAALEb//v3zyl9fzrRp05bbMbt3757+/ft/5v0GDBiQ66677lPnderUKb/+9a+XuH2vvfbKXnvt1Whs1KhRGTVqVPnz4o7z8MMPLzL2fwOabbbZJn/+858bjS18R0tDQ0MOOeSQfOMb3/jEYy/p+M1FyAIAAAAAAEvQv3//QqEHKwcvvgcAAAAAACigWe9kWbBgQUaNGpUbbrghkydPTt++fXPkkUfmzDPPTFVVVZJ/3Sp0zjnn5Oc//3mmT5+ebbbZJldffXXWWWed8jrvv/9+TjrppPz2t79NdXV1RowYkR//+Mfp2LFjc50aAAAAAABNrK6urske3VX0sVwrsqZ6vwr/T7OGLD/4wQ9y9dVXZ+zYsdlggw3yzDPP5Kijjkrnzp3zrW99K0ly8cUX5/LLL8/YsWMzcODAnHXWWRk2bFheeumltGvXLkly6KGHZtKkSZkwYULq6+tz1FFH5bjjjsv48eOb8/QAAAAAAGgidXV1WW/9QZkze1aTrNeutn1e+evLK13QQtNq1pDlsccey957753hw4cnSdZYY43ceOONeeqpp5L86y6Wyy67LGeeeWb23nvvJMn111+fXr165fbbb89BBx2Ul19+Offcc0+efvrpfOELX0iSXHHFFdljjz3y3//93+nbt2/znBwAAAAAAE1m2rRpmTN7Vrrt+e3UdOu3VGvVv/dW3rvzkkybNk3IwlJp1pBl6623zs9+9rP87W9/y7rrrpvnn38+v//973PppZcmSd54441Mnjw5u+66a3mfzp07Z8stt8zjjz+egw46KI8//ni6dOlSDliSZNddd011dXWefPLJ7Lvvvoscd+7cuZk7d27584wZM5Ik9fX1qa+vX1anu9JaeE1dW/h0+gUqp1+gMnoFKqdfoDJ6BSqnX5pWQ0NDamtrs0qv/mnTa82lWmte66rMqq1NQ0ND+ffCpVIpDQ0NaWhoaKKK+SxKpVL5n8vrO2hoaEipVEp9fX1atWrVaFulfdusIcvpp5+eGTNmZP3110+rVq2yYMGCXHjhhTn00EOTJJMnT06S9OrVq9F+vXr1Km+bPHlyevbs2Wh769at07Vr1/Kc/2v06NE599xzFxm/77770r59+6U+LxZvwoQJzV0CrDD0C1ROv0Bl9ApUTr9AZfQKVE6/NJ0bb7zxf/+2YClXGpDsdWPefvvtvP3222ndunV69+6djz/+OPPmzVvaMlkKH3300XI71rx58zJ79uxMnDgx8+fPb7Rt1qzKHkvXrCHLr3/964wbNy7jx4/PBhtskOeeey6nnHJK+vbtmyOOOGKZHfeMM87IyJEjy59nzJiRfv36ZejQoenUqdMyO+7Kqr6+PhMmTMhuu+2Wmpqa5i4HWjT9ApXTL1AZvQKV0y9QGb0CldMvTev555/P9ttvn16HfH/p72SZ8nqmjD89EydOzCabbJI5c+bkrbfeSseOHcvvAmf5KpVK+eijj7LKKqukqqpquRxzzpw5qa2tzfbbb7/I977wCVifpllDltNOOy2nn356DjrooCTJRhttlDfffDOjR4/OEUcckd69eydJpkyZkj59+pT3mzJlSjbddNMkSe/evTN16tRG686fPz/vv/9+ef//q23btmnbtu0i4zU1Nf7HbhlyfaFy+gUqp1+gMnoFKqdfoDJ6BSqnX5pGdXV1Zs+enTnzSyktWLpfws+dX8rs2bNTXV2dmpqaLFiwIFVVVamurk51dXWjuXV1dZk2bdpSHe+z6N69+0r5npiFjwhb+D0sD9XV1amqqlpsj1bas80assyaNWuRi9WqVavyxRw4cGB69+6dBx54oByqzJgxI08++WSOP/74JMmQIUMyffr0PPvss9liiy2SJA8++GAaGhqy5ZZbLr+TAQAAAADgc6Wuri6D1l8vs2bPWW7HbF/bLi//9ZWVMmgpoqqqKrfddlv22WefZjl+s4Yse+21Vy688ML0798/G2ywQf70pz/l0ksvzdFHH53kXxfnlFNOyQUXXJB11lknAwcOzFlnnZW+ffuWL9igQYPypS99Kccee2yuueaa1NfX58QTT8xBBx2Uvn37NuPZAQAAAACwIps2bVpmzZ6TG/atzaAey/7uipffbchht83OtGnTPlPI8u677+bss8/O7373u0yZMiWrrrpqNtlkk5x99tnZZpttlmHFTe/hhx/OLrvskg8++CBdunT51PmTJk3KqquuuuwLW4JmDVmuuOKKnHXWWfnmN7+ZqVOnpm/fvvn617+es88+uzznu9/9bmbOnJnjjjsu06dPz7bbbpt77rmn0fPRxo0blxNPPDG77LJLqqurM2LEiFx++eXNcUoAAAAAAHzODOpRnc37tGruMpZoxIgRmTdvXsaOHZs111wzU6ZMyQMPPJD33nuvuUtbZubNm5c2bdos8bUhy8vyebDZEqyyyiq57LLL8uabb2b27Nn5+9//ngsuuCBt2rQpz6mqqsp5552XyZMnZ86cObn//vuz7rrrNlqna9euGT9+fD766KN8+OGH+cUvfpGOHTsu79MBAAAAAIDlavr06Xn00Ufzgx/8IDvttFMGDBiQL37xiznjjDPy5S9/OUcffXT23HPPRvvU19enZ8+eufbaa5MkO+64Y0466aSccsopWXXVVdOrV6/8/Oc/z8yZM3PUUUdllVVWydprr5277767vMbDDz+cqqqq3Hvvvdlss81SW1ubnXfeOVOnTs3dd9+dQYMGpVOnTjnkkEMya9as8n4NDQ0ZPXp0Bg4cmNra2myyySa55ZZbkvzr8Wy77LJLkmTVVVdNVVVVjjzyyHKNJ554Yk455ZR07949w4YNS/KvDOH2228vr//Pf/4zBx98cLp27ZoOHTrkC1/4Qp588skmv+4LNWvIAgAAAAAAFNexY8d07Ngxt99+e+bOnbvI9q997Wu55557MmnSpPLYnXfemVmzZuXAAw8sj40dOzbdu3fPU089lZNOOinHH3989t9//2y99db54x//mKFDh+arX/1qo8AkSUaNGpWf/OQneeyxx/LWW2/lgAMOyGWXXZbx48fnd7/7Xe67775cccUV5fmjR4/O9ddfn2uuuSYvvvhiTj311Bx22GF55JFHstpqq+Xmm29OkrzyyiuZNGlSfvzjHzeqsU2bNvnDH/6Qa665ZpFz/fjjj7PDDjvk7bffzh133JHnn38+3/3ud8vvgV8WhCwAAAAAALCCat26da677rqMHTs2Xbp0yTbbbJP//M//zJ///OckydZbb5311lsvv/zlL8v7jBkzJvvvv3+jJ0JtsskmOfPMM7POOuvkjDPOSLt27dK9e/cce+yxWWeddXL22WfnvffeK6+70AUXXJBtttkmm222WY455pg88sgjufrqq7PZZptlu+22y1e+8pU89NBDSZK5c+fmoosuyi9+8YsMGzYsa665Zo488sgcdthh+dnPfpZWrVqla9euSZKePXumd+/e6dy5c/lY66yzTi6++OKst956WW+99Ra5FuPHj8+7776b22+/Pdtuu23WXnvtHHDAARkyZEjTXfD/Q8gCAAAAAAArsBEjRuSdd97JHXfckS996Ut5+OGHs/nmm+e6665L8q+7WcaMGZMkmTJlSu6+++4cffTRjdbYeOONy39v1apVunXrlo022qg81qtXryTJ1KlTl7hfr1690r59+6y55pqNxhbu89prr2XWrFnZbbfdynfgdOzYMddff31ef/31Tz3PLbbY4hO3P/fcc9lss83KQc3y0KwvvgcAAAAAAJZeu3btsttuu2W33XbLWWedla997Ws555xzcuSRR+bwww/P6aefnscffzyPPfZYBg4cmO22267R/jU1NY0+V1VVNRqrqqpKkkUevfV/5yxunYX7fPzxx0mS3/3ud1lttdU+8fiL06FDh0/cXltb+6lrNDV3sgAAAAAAwOfM4MGDM3PmzCRJt27dss8++2TMmDG57rrrctRRRzVbTW3btk1dXV3WXnvtRn/69euXJGnTpk2SZMGCBZ95/Y033jjPPfdc3n///Sat+5O4kwUAAAAAAD7By+8uuxenL+1x3nvvvey///45+uijs/HGG2eVVVbJM888k4svvjh77713ed7Xvva17LnnnlmwYEGOOOKIpiy7Yqusskq+853v5NRTT01DQ0O23XbbfPjhh/nDH/6Qjh07Zt99982AAQNSVVWVO++8M3vssUdqa2sbvTvmkxx88MG56KKLss8++2T06NHp06dP/vSnP6Vv377L7L0sQhYAAAAAAFiM7t27p31tuxx22+zldsz2tf964XylOnbsmC233DI/+tGP8ve//z319fXp169fjj322Pznf/5ned6uu+6aPn36ZIMNNkjfvn2XRekVOf/889OjR4+MHj06r7/+erp06ZLNN988p59+epJktdVWy7nnnpvTTz89Rx11VA4//PDyu2U+TZs2bXLffffl29/+dvbYY4/Mnz8/gwcPzpVXXrnMzkfIAgAAAAAAi9G/f/+8/NdXMm3atOV2zO7du6d///4Vz2/btm1Gjx6d0aNHf+K8mTNn5oMPPsgxxxyzyLaHH354kbF//OMfi4yVSqXy33fcccdGn5PkyCOPzJFHHtlobNSoURk1alT5c1VVVU4++eScfPLJjeY1NDRkxowZSZKzzjorZ5111qfW+H9rSpIBAwbklltuWezcZUHIAgAAAAAAS9C/f//PFHq0NA0NDZk2bVouueSSdOnSJV/+8pebu6TPFSELAAAAAAB8TtXV1WXgwIFZffXVc91116V1a7FAU3I1AQAAAADgc2qNNdZY5JFaNJ3q5i4AAAAAAABgRSRkAQAAAACALPoSdT7fmuL7FrIAAAAAALBSq6mpSZLMmjWrmStheVr4fS/8/ovwThYAAAAAAFZqrVq1SpcuXTJ16tQkSfv27VNVVdXMVa1cGhoaMm/evMyZMyfV1cv2/pBSqZRZs2Zl6tSp6dKlS1q1alV4LSELAAAAAAArvd69eydJOWhh+SqVSpk9e3Zqa2uXW8DVpUuX8vdelJAFAAAAAICVXlVVVfr06ZOePXumvr6+uctZ6dTX12fixInZfvvtl+rxXZWqqalZqjtYFhKyAAAAAADA/2rVqlWT/PKdz6ZVq1aZP39+2rVrt1xClqbixfcAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAApo1pBljTXWSFVV1SJ/TjjhhCTJnDlzcsIJJ6Rbt27p2LFjRowYkSlTpjRao66uLsOHD0/79u3Ts2fPnHbaaZk/f35znA4AAAAAALASadaQ5emnn86kSZPKfyZMmJAk2X///ZMkp556an7729/m5ptvziOPPJJ33nkn++23X3n/BQsWZPjw4Zk3b14ee+yxjB07Ntddd13OPvvsZjkfAAAAAABg5dGsIUuPHj3Su3fv8p8777wza621VnbYYYd8+OGHufbaa3PppZdm5513zhZbbJExY8bkscceyxNPPJEkue+++/LSSy/lhhtuyKabbprdd989559/fq688srMmzevOU8NAAAAAAD4nGvd3AUsNG/evNxwww0ZOXJkqqqq8uyzz6a+vj677rprec7666+f/v375/HHH89WW22Vxx9/PBtttFF69epVnjNs2LAcf/zxefHFF7PZZpst9lhz587N3Llzy59nzJiRJKmvr099ff0yOsOV18Jr6trCp9MvUDn9ApXRK1A5/QKV0StQOf3StBoaGlJbW5t2ravSplVpqdaqal2V2traNDQ0+H5aiJbWL5XW0WJClttvvz3Tp0/PkUcemSSZPHly2rRpky5dujSa16tXr0yePLk8598DloXbF25bktGjR+fcc89dZPy+++5L+/btl+Is+CQLHwcHfDr9ApXTL1AZvQKV0y9QGb0CldMvTefGG2/8378tWMqVBiR73Zi33347b7/99tKWRRNqKf0ya9asiua1mJDl2muvze67756+ffsu82OdccYZGTlyZPnzjBkz0q9fvwwdOjSdOnVa5sdf2dTX12fChAnZbbfdUlNT09zlQIumX6By+gUqo1egcvoFKqNXoHL6pWk9//zz2X777dPrkO+nTa81l2qteVNez5Txp2fixInZZJNNmqhClkZL65eFT8D6NC0iZHnzzTdz//3359Zbby2P9e7dO/Pmzcv06dMb3c0yZcqU9O7duzznqaeearTWlClTytuWpG3btmnbtu0i4zU1NS3iy/u8cn2hcvoFKqdfoDJ6BSqnX6AyegUqp1+aRnV1dWbPnp0580spLahaqrXmzi9l9uzZqa6u9t20MC2lXyqtoVlffL/QmDFj0rNnzwwfPrw8tsUWW6SmpiYPPPBAeeyVV15JXV1dhgwZkiQZMmRIXnjhhUydOrU8Z8KECenUqVMGDx68/E4AAAAAAABY6TT7nSwNDQ0ZM2ZMjjjiiLRu/f/K6dy5c4455piMHDkyXbt2TadOnXLSSSdlyJAh2WqrrZIkQ4cOzeDBg/PVr341F198cSZPnpwzzzwzJ5xwwmLvVAEAAAAAAGgqzR6y3H///amrq8vRRx+9yLYf/ehHqa6uzogRIzJ37twMGzYsV111VXl7q1atcuedd+b444/PkCFD0qFDhxxxxBE577zzlucpAAAAAAAAK6FmD1mGDh2aUqm02G3t2rXLlVdemSuvvHKJ+w8YMCB33XXXsioPAAAAAABgsVrEO1kAAAAAAABWNEIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABTQ7CHL22+/ncMOOyzdunVLbW1tNtpoozzzzDPl7aVSKWeffXb69OmT2tra7Lrrrnn11VcbrfH+++/n0EMPTadOndKlS5ccc8wx+fjjj5f3qQAAAAAAACuRZg1ZPvjgg2yzzTapqanJ3XffnZdeeimXXHJJVl111fKciy++OJdffnmuueaaPPnkk+nQoUOGDRuWOXPmlOcceuihefHFFzNhwoTceeedmThxYo477rjmOCUAAAAAAGAl0bo5D/6DH/wg/fr1y5gxY8pjAwcOLP+9VCrlsssuy5lnnpm99947SXL99denV69euf3223PQQQfl5Zdfzj333JOnn346X/jCF5IkV1xxRfbYY4/893//d/r27bt8TwoAAAAAAFgpNGvIcscdd2TYsGHZf//988gjj2S11VbLN7/5zRx77LFJkjfeeCOTJ0/OrrvuWt6nc+fO2XLLLfP444/noIMOyuOPP54uXbqUA5Yk2XXXXVNdXZ0nn3wy++677yLHnTt3bubOnVv+PGPGjCRJfX196uvrl9XprrQWXlPXFj6dfoHK6ReojF6ByukXqIxegcrpl6bV0NCQ2tratGtdlTatSku1VlXrqtTW1qahocH300K0tH6ptI6qUqm0dD+NS6Fdu3ZJkpEjR2b//ffP008/nZNPPjnXXHNNjjjiiDz22GPZZptt8s4776RPnz7l/Q444IBUVVXlV7/6VS666KKMHTs2r7zySqO1e/bsmXPPPTfHH3/8IscdNWpUzj333EXGx48fn/bt2zfxWQIAAAAAACuSWbNm5ZBDDsmHH36YTp06LXFes97J0tDQkC984Qu56KKLkiSbbbZZ/vKXv5RDlmXljDPOyMiRI8ufZ8yYkX79+mXo0KGfeLEopr6+PhMmTMhuu+2Wmpqa5i4HWjT9ApXTL1AZvQKV0y9QGb0CldMvTev555/P9ttvn16HfD9teq25VGvNm/J6pow/PRMnTswmm2zSRBWyNFpavyx8AtanadaQpU+fPhk8eHCjsUGDBuU3v/lNkqR3795JkilTpjS6k2XKlCnZdNNNy3OmTp3aaI358+fn/fffL+//f7Vt2zZt27ZdZLympqZFfHmfV64vVE6/QOX0C1RGr0Dl9AtURq9A5fRL06iurs7s2bMzZ34ppQVVS7XW3PmlzJ49O9XV1b6bFqal9EulNVQv4zo+0TbbbLPIY77+9re/ZcCAAUmSgQMHpnfv3nnggQfK22fMmJEnn3wyQ4YMSZIMGTIk06dPz7PPPlue8+CDD6ahoSFbbrnlcjgLAAAAAABgZdSsd7Kceuqp2XrrrXPRRRflgAMOyFNPPZWf/exn+dnPfpYkqaqqyimnnJILLrgg66yzTgYOHJizzjorffv2zT777JPkX3e+fOlLX8qxxx6ba665JvX19TnxxBNz0EEHpW/fvs14dgAAAAAAwOdZs4Ys//Ef/5HbbrstZ5xxRs4777wMHDgwl112WQ499NDynO9+97uZOXNmjjvuuEyfPj3bbrtt7rnnnrRr1648Z9y4cTnxxBOzyy67pLq6OiNGjMjll1/eHKcEAAAAAACsJJo1ZEmSPffcM3vuuecSt1dVVeW8887Leeedt8Q5Xbt2zfjx45dFeQAAAAAAAIvVrO9kAQAAAAAAWFEJWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQQLOGLKNGjUpVVVWjP+uvv355+5w5c3LCCSekW7du6dixY0aMGJEpU6Y0WqOuri7Dhw9P+/bt07Nnz5x22mmZP3/+8j4VAAAAAABgJdO6uQvYYIMNcv/995c/t279/0o69dRT87vf/S4333xzOnfunBNPPDH77bdf/vCHPyRJFixYkOHDh6d379557LHHMmnSpBx++OGpqanJRRddtNzPBQAAAAAAWHk0e8jSunXr9O7de5HxDz/8MNdee23Gjx+fnXfeOUkyZsyYDBo0KE888US22mqr3HfffXnppZdy//33p1evXtl0001z/vnn53vf+15GjRqVNm3aLO/TAQAAAAAAVhLNHrK8+uqr6du3b9q1a5chQ4Zk9OjR6d+/f5599tnU19dn1113Lc9df/31079//zz++OPZaqut8vjjj2ejjTZKr169ynOGDRuW448/Pi+++GI222yzxR5z7ty5mTt3bvnzjBkzkiT19fWpr69fRme68lp4TV1b+HT6BSqnX6AyegUqp1+gMnoFKqdfmlZDQ0Nqa2vTrnVV2rQqLdVaVa2rUltbm4aGBt9PC9HS+qXSOqpKpdLS/TQuhbvvvjsff/xx1ltvvUyaNCnnnntu3n777fzlL3/Jb3/72xx11FGNwpAk+eIXv5iddtopP/jBD3LcccflzTffzL333lvePmvWrHTo0CF33XVXdt9998Ued9SoUTn33HMXGR8/fnzat2/ftCcJAAAAAACsUGbNmpVDDjkkH374YTp16rTEec16J8u/hyAbb7xxttxyywwYMCC//vWvU1tbu8yOe8YZZ2TkyJHlzzNmzEi/fv0ydOjQT7xYFFNfX58JEyZkt912S01NTXOXAy2afoHK6ReojF6ByukXqIxegcrpl6b1/PPPZ/vtt0+vQ76fNr3WXKq15k15PVPGn56JEydmk002aaIKWRotrV8WPgHr0zT748L+XZcuXbLuuuvmtddey2677ZZ58+Zl+vTp6dKlS3nOlClTyu9w6d27d5566qlGa0yZMqW8bUnatm2btm3bLjJeU1PTIr68zyvXFyqnX6By+gUqo1egcvoFKqNXoHL6pWlUV1dn9uzZmTO/lNKCqqVaa+78UmbPnp3q6mrfTQvTUvql0hqql3Edn8nHH3+cv//97+nTp0+22GKL1NTU5IEHHihvf+WVV1JXV5chQ4YkSYYMGZIXXnghU6dOLc+ZMGFCOnXqlMGDBy/3+gEAAAAAgJVHs97J8p3vfCd77bVXBgwYkHfeeSfnnHNOWrVqlYMPPjidO3fOMccck5EjR6Zr167p1KlTTjrppAwZMiRbbbVVkmTo0KEZPHhwvvrVr+biiy/O5MmTc+aZZ+aEE05Y7J0qAAAAAAAATaVZQ5Z//vOfOfjgg/Pee++lR48e2XbbbfPEE0+kR48eSZIf/ehHqa6uzogRIzJ37twMGzYsV111VXn/Vq1a5c4778zxxx+fIUOGpEOHDjniiCNy3nnnNdcpAQAAAAAAK4lmDVluuummT9zerl27XHnllbnyyiuXOGfAgAG56667mro0AAAAAACAT9Si3skCAAAAAACwohCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFFApZXn/99aauAwAAAAAAYIVSKGRZe+21s9NOO+WGG27InDlzmromAAAAAACAFq9QyPLHP/4xG2+8cUaOHJnevXvn61//ep566qmmrg0AAAAAAKDFKhSybLrppvnxj3+cd955J7/4xS8yadKkbLvtttlwww1z6aWX5t13323qOgEAAAAAAFqUpXrxfevWrbPffvvl5ptvzg9+8IO89tpr+c53vpN+/frl8MMPz6RJk5qqTgAAAAAAgBZlqUKWZ555Jt/85jfTp0+fXHrppfnOd76Tv//975kwYULeeeed7L333k1VJwAAAAAAQIvSushOl156acaMGZNXXnkle+yxR66//vrsscceqa7+V2YzcODAXHfddVljjTWaslYAAAAAAIAWo1DIcvXVV+foo4/OkUcemT59+ix2Ts+ePXPttdcuVXEAAAAAAAAtVaGQ5dVXX/3UOW3atMkRRxxRZHkAAAAAAIAWr9A7WcaMGZObb755kfGbb745Y8eOXeqiAAAAAAAAWrpCIcvo0aPTvXv3RcZ79uyZiy66aKmLAgAAAAAAaOkKhSx1dXUZOHDgIuMDBgxIXV3dUhcFAAAAAADQ0hUKWXr27Jk///nPi4w///zz6dat21IXBQAAAAAA0NIVClkOPvjgfOtb38pDDz2UBQsWZMGCBXnwwQdz8skn56CDDmrqGgEAAAAAAFqc1kV2Ov/88/OPf/wju+yyS1q3/tcSDQ0NOfzww72TBQAAAAAAWCkUClnatGmTX/3qVzn//PPz/PPPp7a2NhtttFEGDBjQ1PUBAAAAAAC0SIVCloXWXXfdrLvuuk1VCwAAAAAAwAqjUMiyYMGCXHfddXnggQcyderUNDQ0NNr+4IMPNklxAAAAAAAALVWhkOXkk0/Oddddl+HDh2fDDTdMVVVVU9cFAAAAAADQohUKWW666ab8+te/zh577NHU9QAAAAAAAKwQqovs1KZNm6y99tpNXQsAAAAAAMAKo1DI8u1vfzs//vGPUyqVmroeAAAAAACAFUKhx4X9/ve/z0MPPZS77747G2ywQWpqahptv/XWW5ukOAAAAAAAgJaqUMjSpUuX7Lvvvk1dCwAAAAAAwAqjUMgyZsyYpq4DAAAAAABghVLonSxJMn/+/Nx///356U9/mo8++ihJ8s477+Tjjz9usuIAAAAAAABaqkJ3srz55pv50pe+lLq6usydOze77bZbVllllfzgBz/I3Llzc8011zR1nQAAAAAAAC1KoTtZTj755HzhC1/IBx98kNra2vL4vvvumwceeKDJigMAAAAAAGipCt3J8uijj+axxx5LmzZtGo2vscYaefvtt5ukMAAAAAAAgJas0J0sDQ0NWbBgwSLj//znP7PKKqssdVEAAAAAAAAtXaGQZejQobnsssvKn6uqqvLxxx/nnHPOyR577NFUtQEAAAAAALRYhR4Xdskll2TYsGEZPHhw5syZk0MOOSSvvvpqunfvnhtvvLGpawQAAAAAAGhxCoUsq6++ep5//vncdNNN+fOf/5yPP/44xxxzTA499NDU1tY2dY0AAAAAAAAtTqGQJUlat26dww47rClrAQAAAAAAWGEUClmuv/76T9x++OGHFyoGAAAAAABgRVEoZDn55JMbfa6vr8+sWbPSpk2btG/fXsgCAAAAAAB87lUX2emDDz5o9Ofjjz/OK6+8km233daL7wEAAAAAgJVCoZBlcdZZZ518//vfX+QuFwAAAAAAgM+jJgtZkqR169Z55513mnJJAAAAAACAFqnQO1nuuOOORp9LpVImTZqUn/zkJ9lmm22apDAAAAAAAICWrFDIss8++zT6XFVVlR49emTnnXfOJZdc0hR1AQAAAAAAtGiFQpaGhoamrgMAAAAAAGCF0qTvZAEAAAAAAFhZFLqTZeTIkRXPvfTSS4scAgAAAAAAoEUrdCfLn/70p/ziF7/IT3/60zz88MN5+OGH87Of/SzXXntt/vSnP5X/PPfccxWv+f3vfz9VVVU55ZRTymNz5szJCSeckG7duqVjx44ZMWJEpkyZ0mi/urq6DB8+PO3bt0/Pnj1z2mmnZf78+UVOCwAAAAAAoGKF7mTZa6+9ssoqq2Ts2LFZddVVkyQffPBBjjrqqGy33Xb59re//ZnWe/rpp/PTn/40G2+8caPxU089Nb/73e9y8803p3PnzjnxxBOz33775Q9/+EOSZMGCBRk+fHh69+6dxx57LJMmTcrhhx+empqaXHTRRUVODQAAAAAAoCKF7mS55JJLMnr06HLAkiSrrrpqLrjgglxyySWfaa2PP/44hx56aH7+8583Wu/DDz/Mtddem0svvTQ777xztthii4wZMyaPPfZYnnjiiSTJfffdl5deeik33HBDNt100+y+++45//zzc+WVV2bevHlFTg0AAAAAAKAihe5kmTFjRt59991Fxt9999189NFHn2mtE044IcOHD8+uu+6aCy64oDz+7LPPpr6+Prvuumt5bP3110///v3z+OOPZ6uttsrjjz+ejTbaKL169SrPGTZsWI4//vi8+OKL2WyzzRZ7zLlz52bu3LmNzidJ6uvrU19f/5nq59MtvKauLXw6/QKV0y9QGb0CldMvUBm9ApXTL02roaEhtbW1ade6Km1alZZqrarWVamtrU1DQ4Pvp4Voaf1SaR2FQpZ99903Rx11VC655JJ88YtfTJI8+eSTOe2007LffvtVvM5NN92UP/7xj3n66acX2TZ58uS0adMmXbp0aTTeq1evTJ48uTzn3wOWhdsXbluS0aNH59xzz11k/L777kv79u0rrp/PZsKECc1dAqww9AtUTr9AZfQKVE6/QGX0ClROvzSdG2+88X//tmApVxqQ7HVj3n777bz99ttLWxZNqKX0y6xZsyqaVyhkueaaa/Kd73wnhxxySDnNad26dY455pj88Ic/rGiNt956KyeffHImTJiQdu3aFSmjsDPOOCMjR44sf54xY0b69euXoUOHplOnTsu1lpVBfX19JkyYkN122y01NTXNXQ60aPoFKqdfoDJ6BSqnX6AyegUqp1+a1vPPP5/tt98+vQ75ftr0WnOp1po35fVMGX96Jk6cmE022aSJKmRptLR+WfgErE9TKGRp3759rrrqqvzwhz/M3//+9yTJWmutlQ4dOlS8xrPPPpupU6dm8803L48tWLAgEydOzE9+8pPce++9mTdvXqZPn97obpYpU6akd+/eSZLevXvnqaeearTulClTytuWpG3btmnbtu0i4zU1NS3iy/u8cn2hcvoFKqdfoDJ6BSqnX6AyegUqp1+aRnV1dWbPnp0580spLahaqrXmzi9l9uzZqa6u9t20MC2lXyqtodCL7xeaNGlSJk2alHXWWScdOnRIqVT5c/B22WWXvPDCC3nuuefKf77whS/k0EMPLf+9pqYmDzzwQHmfV155JXV1dRkyZEiSZMiQIXnhhRcyderU8pwJEyakU6dOGTx48NKcGgAAAAAAwCcqdCfLe++9lwMOOCAPPfRQqqqq8uqrr2bNNdfMMccck1VXXTWXXHLJp66xyiqrZMMNN2w01qFDh3Tr1q08fswxx2TkyJHp2rVrOnXqlJNOOilDhgzJVlttlSQZOnRoBg8enK9+9au5+OKLM3ny5Jx55pk54YQTFnunCgAAAAAAQFMpdCfLqaeempqamtTV1TV6UfyBBx6Ye+65p8mK+9GPfpQ999wzI0aMyPbbb5/evXvn1ltvLW9v1apV7rzzzrRq1SpDhgzJYYcdlsMPPzznnXdek9UAAAAAAACwOIXuZLnvvvty7733ZvXVV280vs466+TNN98sXMzDDz/c6HO7du1y5ZVX5sorr1ziPgMGDMhdd91V+JgAAAAAAABFFLqTZebMmY3uYFno/fff95guAAAAAABgpVAoZNluu+1y/fXXlz9XVVWloaEhF198cXbaaacmKw4AAAAAAKClKvS4sIsvvji77LJLnnnmmcybNy/f/e538+KLL+b999/PH/7wh6auEQAAAAAAoMUpdCfLhhtumL/97W/Zdttts/fee2fmzJnZb7/98qc//SlrrbVWU9cIAAAAAADQ4nzmO1nq6+vzpS99Kddcc03+67/+a1nUBAAAAAAA0OJ95jtZampq8uc//3lZ1AIAAAAAALDCKPS4sMMOOyzXXnttU9cCAAAAAACwwij04vv58+fnF7/4Re6///5sscUW6dChQ6Ptl156aZMUBwAAAAAA0FJ9ppDl9ddfzxprrJG//OUv2XzzzZMkf/vb3xrNqaqqarrqAAAAAAAAWqjPFLKss846mTRpUh566KEkyYEHHpjLL788vXr1WibFAQAAAAAAtFSf6Z0spVKp0ee77747M2fObNKCAAAAAAAAVgSFXny/0P8NXQAAAAAAAFYWnylkqaqqWuSdK97BAgAAAAAArIw+0ztZSqVSjjzyyLRt2zZJMmfOnHzjG99Ihw4dGs279dZbm65CAAAAAACAFugzhSxHHHFEo8+HHXZYkxYDAAAAAACwovhMIcuYMWOWVR0AAAAAAAArlKV68T0AAAAAAMDKSsgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIACmjVkufrqq7PxxhunU6dO6dSpU4YMGZK77767vH3OnDk54YQT0q1bt3Ts2DEjRozIlClTGq1RV1eX4cOHp3379unZs2dOO+20zJ8/f3mfCgAAAAAAsJJp1pBl9dVXz/e///08++yzeeaZZ7Lzzjtn7733zosvvpgkOfXUU/Pb3/42N998cx555JG888472W+//cr7L1iwIMOHD8+8efPy2GOPZezYsbnuuuty9tlnN9cpAQAAAAAAK4nWzXnwvfbaq9HnCy+8MFdffXWeeOKJrL766rn22mszfvz47LzzzkmSMWPGZNCgQXniiSey1VZb5b777stLL72U+++/P7169cqmm26a888/P9/73vcyatSotGnTpjlOCwAAAAAAWAk0a8jy7xYsWJCbb745M2fOzJAhQ/Lss8+mvr4+u+66a3nO+uuvn/79++fxxx/PVlttlccffzwbbbRRevXqVZ4zbNiwHH/88XnxxRez2WabLfZYc+fOzdy5c8ufZ8yYkSSpr69PfX39MjrDldfCa+rawqfTL1A5/QKV0StQOf0CldErUDn90rQaGhpSW1ubdq2r0qZVaanWqmpdldra2jQ0NPh+WoiW1i+V1tHsIcsLL7yQIUOGZM6cOenYsWNuu+22DB48OM8991zatGmTLl26NJrfq1evTJ48OUkyefLkRgHLwu0Lty3J6NGjc+655y4yft9996V9+/ZLeUYsyYQJE5q7BFhh6BeonH6ByugVqJx+gcroFaicfmk6N9544//+bcFSrjQg2evGvP3223n77beXtiyaUEvpl1mzZlU0r9lDlvXWWy/PPfdcPvzww9xyyy054ogj8sgjjyzTY55xxhkZOXJk+fOMGTPSr1+/DB06NJ06dVqmx14Z1dfXZ8KECdltt91SU1PT3OVAi6ZfoHL6BSqjV6By+gUqo1egcvqlaT3//PPZfvvt0+uQ76dNrzWXaq15U17PlPGnZ+LEidlkk02aqEKWRkvrl4VPwPo0zR6ytGnTJmuvvXaSZIsttsjTTz+dH//4xznwwAMzb968TJ8+vdHdLFOmTEnv3r2TJL17985TTz3VaL0pU6aUty1J27Zt07Zt20XGa2pqWsSX93nl+kLl9AtUTr9AZfQKVE6/QGX0ClROvzSN6urqzJ49O3Pml1JaULVUa82dX8rs2bNTXV3tu2lhWkq/VFpD9TKu4zNraGjI3Llzs8UWW6SmpiYPPPBAedsrr7ySurq6DBkyJEkyZMiQvPDCC5k6dWp5zoQJE9KpU6cMHjx4udcOAAAAAACsPJr1TpYzzjgju+++e/r375+PPvoo48ePz8MPP5x77703nTt3zjHHHJORI0ema9eu6dSpU0466aQMGTIkW221VZJk6NChGTx4cL761a/m4osvzuTJk3PmmWfmhBNOWOydKgAAAAAAAE2lWUOWqVOn5vDDD8+kSZPSuXPnbLzxxrn33nuz2267JUl+9KMfpbq6OiNGjMjcuXMzbNiwXHXVVeX9W7VqlTvvvDPHH398hgwZkg4dOuSII47Ieeed11ynBAAAAAAArCSaNWS59tprP3F7u3btcuWVV+bKK69c4pwBAwbkrrvuaurSAAAAAAAAPlGLeycLAAAAAADAikDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABrZu7AAAAAAAAVkx1dXWZNm1ak6zVvXv39O/fv0nWguVFyAIAAAAAwGdWV1eXQeuvl1mz5zTJeu1r2+Xlv74iaGGFImQBAAAAAOAzmzZtWmbNnpMb9q3NoB5L92aKl99tyGG3zc60adOELKxQhCwAAAAAABQ2qEd1Nu/TqrnLgGbhxfcAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAJaN3cBAAAAAADQHF5++eUmWad79+7p379/k6zFikXIAgAAAADASmXBxx+kuio57LDDmmS99rXt8vJfXxG0rISELAAAAAAArFQa5n6chlJyw761GdRj6d6q8fK7DTnsttmZNm2akGUlJGQBAAAAAGClNKhHdTbv06q5y2AF5sX3AAAAAAAABTRryDJ69Oj8x3/8R1ZZZZX07Nkz++yzT1555ZVGc+bMmZMTTjgh3bp1S8eOHTNixIhMmTKl0Zy6uroMHz487du3T8+ePXPaaadl/vz5y/NUAAAAAACAlUyzhiyPPPJITjjhhDzxxBOZMGFC6uvrM3To0MycObM859RTT81vf/vb3HzzzXnkkUfyzjvvZL/99itvX7BgQYYPH5558+blsccey9ixY3Pdddfl7LPPbo5TAgAAAAAAVhLN+k6We+65p9Hn6667Lj179syzzz6b7bffPh9++GGuvfbajB8/PjvvvHOSZMyYMRk0aFCeeOKJbLXVVrnvvvvy0ksv5f7770+vXr2y6aab5vzzz8/3vve9jBo1Km3atFnkuHPnzs3cuXPLn2fMmJEkqa+vT319/TI845XTwmvq2sKn0y9QOf0CldErUDn9ApXRK1C5z3u/NDQ0pLa2Ng2ta1NfvXT/PX9D64bU1jakoaFhiddr4fHata5Km1alpTre/JpWy7V2Pl1L65dK66gqlUpL99PYhF577bWss846eeGFF7LhhhvmwQcfzC677JIPPvggXbp0Kc8bMGBATjnllJx66qk5++yzc8cdd+S5554rb3/jjTey5ppr5o9//GM222yzRY4zatSonHvuuYuMjx8/Pu3bt18WpwYAAAAAAKwgZs2alUMOOSQffvhhOnXqtMR5zXony79raGjIKaeckm222SYbbrhhkmTy5Mlp06ZNo4AlSXr16pXJkyeX5/Tq1WuR7Qu3Lc4ZZ5yRkSNHlj/PmDEj/fr1y9ChQz/xYlFMfX19JkyYkN122y01NTXNXQ60aPoFKqdfoDJ6BSqnX6AyegUq93nvl+effz7bb799Jh7VIZv0Wrq7QZ6f0pDtx8zMxIkTs8kmm3zi8Xod8v206bXmUh1v5suP5v17rlhutfPpWlq/LHwC1qdpMSHLCSeckL/85S/5/e9/v8yP1bZt27Rt23aR8Zqamhbx5X1eub5QOf0CldMvUBm9ApXTL1AZvQKV+7z2S3V1dWbPnp3q+dWpaWi1dGvNX/Cvtaqrl3itFh5vzvxSSguqlup4c+oXLNfaqVxL6ZdKa2jWF98vdOKJJ+bOO+/MQw89lNVXX7083rt378ybNy/Tp09vNH/KlCnp3bt3ec6UKVMW2b5wGwAAAAAAwLLQrCFLqVTKiSeemNtuuy0PPvhgBg4c2Gj7FltskZqamjzwwAPlsVdeeSV1dXUZMmRIkmTIkCF54YUXMnXq1PKcCRMmpFOnThk8ePDyOREAAAAAAGCl06yPCzvhhBMyfvz4/H//3/+XVVZZpfwOlc6dO6e2tjadO3fOMccck5EjR6Zr167p1KlTTjrppAwZMiRbbbVVkmTo0KEZPHhwvvrVr+biiy/O5MmTc+aZZ+aEE05Y7CPBAAAAAAAAmkKzhixXX311kmTHHXdsND5mzJgceeSRSZIf/ehHqa6uzogRIzJ37twMGzYsV111VXluq1atcuedd+b444/PkCFD0qFDhxxxxBE577zzltdpAAAAAAAAK6FmDVlKpdKnzmnXrl2uvPLKXHnllUucM2DAgNx1111NWRoAAAAAwOdSXV1dpk2bttTrvPzyy01QDazYmjVkAQAAAABg+amrq8t66w/KnNmzmrsU+FwQsgAAAAAArCSmTZuWObNnpdue305Nt35Ltdbs15/Jh4/e0ESVwYpJyAIAAAAAsJKp6dYvbXuvvVRr1L/3VhNVAyuu6uYuAAAAAAAAYEUkZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAKELAAAAAAAAAUIWQAAAAAAAAoQsgAAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIACWjd3AQAAAAAAK6u6urpMmzatSdbq3r17+vfv3yRrAZURsgAAAAAANIO6uroMWn+9zJo9p0nWa1/bLi//9RVBCyxHQhYAAAAAgGYwbdq0zJo9JzfsW5tBPZbuzQ4vv9uQw26bnWnTpglZYDkSsgAAAAAANKNBPaqzeZ9WzV0GUIAX3wMAAAAAABQgZAEAAAAAAChAyAIAAAAAAFCAkAUAAAAAAKAAIQsAAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoIDWzV0AAAAAAMDSqKury7Rp05pkre7du6d///5Nshbw+SdkAQAAAABWWHV1dRm0/nqZNXtOk6zXvrZdXv7rK4IWoCJCFgAAAABghTVt2rTMmj0nN+xbm0E9lu7tCC+/25DDbpudadOmCVmAijTrO1kmTpyYvfbaK3379k1VVVVuv/32RttLpVLOPvvs9OnTJ7W1tdl1113z6quvNprz/vvv59BDD02nTp3SpUuXHHPMMfn444+X41kAAAAAAM1tUI/qbN6n1VL9WdqQBlj5NOv/asycOTObbLJJrrzyysVuv/jii3P55ZfnmmuuyZNPPpkOHTpk2LBhmTPn/936d+ihh+bFF1/MhAkTcuedd2bixIk57rjjltcpAAAAAAAAK6lmfVzY7rvvnt13332x20qlUi677LKceeaZ2XvvvZMk119/fXr16pXbb789Bx10UF5++eXcc889efrpp/OFL3whSXLFFVdkjz32yH//93+nb9++y+1cAAAAAACAlUuLfSfLG2+8kcmTJ2fXXXctj3Xu3DlbbrllHn/88Rx00EF5/PHH06VLl3LAkiS77rprqqur8+STT2bfffdd7Npz587N3Llzy59nzJiRJKmvr099ff0yOqOV18Jr6trCp9MvUDn9ApXRK1A5/QKV0Su0NA0NDamtrU1D69rUVy/dg3saWjektrYhDQ0NTfIz/mn90hy1Lzxmu9ZVadOqtFTHnF/TarnWvyLXzqdraf9+qbSOqlKptHQ/jU2kqqoqt912W/bZZ58kyWOPPZZtttkm77zzTvr06VOed8ABB6Sqqiq/+tWvctFFF2Xs2LF55ZVXGq3Vs2fPnHvuuTn++OMXe6xRo0bl3HPPXWR8/Pjxad++fdOdFAAAAAAAsMKZNWtWDjnkkHz44Yfp1KnTEue12DtZlqUzzjgjI0eOLH+eMWNG+vXrl6FDh37ixaKY+vr6TJgwIbvttltqamqauxxo0fQLVE6/QGX0ClROv0Bl9AotzfPPP5/tt98+E4/qkE16Ld0dCc9Pacj2Y2Zm4sSJ2WSTTZa6tk/rl+aofeExex3y/bTpteZSHXPmy4/m/XuuWG71r8i18+la2r9fFj4B69O02JCld+/eSZIpU6Y0upNlypQp2XTTTctzpk6d2mi/+fPn5/333y/vvzht27ZN27ZtFxmvqalpEV/e55XrC5XTL1A5/QKV0StQOf0CldErtBTV1dWZPXt2qudXp6ah1dKtNX/Bv9aqrm7Sn+8l9Utz1L7wmHPml1JaULVUx5xTv2C51r8i107lWsq/XyqtYekiumVo4MCB6d27dx544IHy2IwZM/Lkk09myJAhSZIhQ4Zk+vTpefbZZ8tzHnzwwTQ0NGTLLbdc7jUDAAAAAAArj2a9k+Xjjz/Oa6+9Vv78xhtv5LnnnkvXrl3Tv3//nHLKKbnggguyzjrrZODAgTnrrLPSt2/f8ntbBg0alC996Us59thjc80116S+vj4nnnhiDjrooPTt27eZzgoAAAAAAFgZNGvI8swzz2SnnXYqf174npQjjjgi1113Xb773e9m5syZOe644zJ9+vRsu+22ueeee9KuXbvyPuPGjcuJJ56YXXbZJdXV1RkxYkQuv/zy5X4uAAAAAADAyqVZQ5Ydd9wxpVJpidurqqpy3nnn5bzzzlvinK5du2b8+PHLojwAAAAAAIAlarHvZAEAAAAAAGjJhCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAoQsAAAAAAAABQhZAAAAAAAAChCyAAAAAAAAFCBkAQAAAAAAKEDIAgAAAAAAUICQBQAAAAAAoAAhCwAAAAAAQAFCFgAAAAAAgAJaN3cBAAAAAEDzq6ury7Rp05pkre7du6d///5NshZASyZkAQAAAICVXF1dXQatv15mzZ7TJOu1r22Xl//6iqAF+NwTsgAAAADASm7atGmZNXtObti3NoN6LN0bBl5+tyGH3TY706ZNE7IAn3tCFgAAAAAgSTKoR3U279OqucsAWGF48T0AAAAAAEABQhYAAAAAAIAChCwAAAAAAAAFCFkAAAAAAAAKELIAAAAAAAAUIGQBAAAAAAAoQMgCAAAAAABQgJAFAAAAAACgACELAAAAAABAAUIWAAAAAACAAlo3dwEAAAAAsFBdXV2mTZvWJGt17949/fv3b5K1AGBxhCwAAAAAtAh1dXUZtP56mTV7TpOs1762XV7+6yuCFgCWGSELAAAAAC3CtP+/vXuPjqK+/z/+SkKySYghQBLCLQhyC1SDBMkvXCRUMCjVxlJKW0Gg1ELVUg3loq2AcpAo4C1FwR4gKLZc2qq0YBQjSeVqGxMVGyLXrggBF4EEEpKQfH5/+GXalduy2WSzyfNxzh6Ymc989j175r0zO+/MZxwOlZWf0+p7QhQXVbtR7gu/qtHYN8rlcDgosgAA6gxFFgAAAAAAADQocVH+6ts2wNthuMVTw50x1BkA+AaKLAAAAAAAAIAHeHK4M4Y6AwDfQJEFAAAAAAAA8ABPDXfGUGcA4DsosgAAAAAAAAAe5MvDnQEArk3tniAGAAAAAAAAAADQRFFkAQAAAAAAAAAAcANFFgAAAAAAAAAAADdQZAEAAAAAAAAAAHADD74HAAAAAABoZOx2uxwOh0f6ioyMVGxsrEf6AgB4Bt/zDQdFFgAAAAAAgEbEbrcrrmcPlZWf80h/oSHBKtxTxAU4AGgg+J5vWCiyAAAAAAAANCIOh0Nl5ee0+p4QxUXVbqT4wq9qNPaNcjkcDi6+AUADwfd8w0KRBQAAAAAAoBGKi/JX37YB3g4DAFBH+J5vGHjwPQAAAAAAAAAAgBsosgAAAAAAAAAAALiB4cIAAAAAAAAuwW63y+FweKSvyMhIxroHAKARosgCAAAAAADwLXa7XXE9e6is/JxH+gsNCVbhniIKLQAANDIUWQAAAAAAQJ3w5TtBHA6HysrPafU9IYqLqt1o64Vf1WjsG+VyOBwUWQAAaGQosgAAAAAAAI9rLHeCxEX5q2/bgHp9TwAA4DsosgAAAAAAAI/jThAAANAUUGQBAAAAAAB1hjtBAABAY1a7PyUBAAAAAAAAAABooiiyAAAAAAAAAAAAuIEiCwAAAAAAAAAAgBsosgAAAAAAAAAAALiBB98DAAAAAFxit9vlcDhq3U9kZKRiY2M9EBEAAIDv8NS5VGFhoQeigadQZAEAAAAAXJXdbldczx4qKz9X675CQ4JVuKeIQouLPHVBRqLABQCAt9jtdvXoGadz5WXeDgUeRpEFAAAAgE/hgrN3OBwOlZWf0+p7QhQX5f7I04Vf1WjsG+VyOBz1+tm7st/U1NRIkj7++GP5+19+G+tzv/FkcUuiwAUAgLc4HA6dKy9T6+9NU2DrjrXqq/zAv3T6g9Ueigy11WiKLEuWLNHChQtVXFys+Ph4ZWRkqH///t4OCwAAAGiQfLVQ4esXnH31c/9fcVH+6ts2oN7ftzZc3W9CQkL0pz/9SbfeeqvKy8sv264+9xtPFbck7xW4AADAfwW27ihbTNda9VF14gsPRQNPaBRFlrVr1yotLU1Lly5VYmKinn/+eaWkpKioqEjR0dHeDg8AUM8awwUsoKnw5Xz19dh9tVDhyxecfflz93Wu7jc1zUL0paR/TGwu//OXbuetQoUvFrcAAACagkZRZHn22Wd1//33a+LEiZKkpUuXauPGjVqxYoVmzZrl5ehwweHDh3Xy5EmP9MVFFPgCd/abyw1RwX7jOl+/gMX3jff48sOcfXW/8eV89eXYJd8uVFzgixecG8Pn7uuutt9U+fvrS0nxbfwVWONb+xcAAAC8w+eLLJWVlcrLy9Ojjz5qzfP399ewYcO0Y8eOS65TUVGhiooKa/r06dOSpK+//lpVVVV1G7CPOX78uI4dO1arPmpqalRWVqaBSf9PJ0+XeCSukJBg5eTkqn379pdt44nYL/QzZfIvVH6u4uqNXeBK7Bfe1xPxS9/kxIWL97XVpk2bq94hRuzu7zchISFasmSJbr/9dqchKup7v6nvz13yXOx79+5VjZFmDglXh/DaXcA6XFKjF3ZV6sCBA2revPll23l7v7mc+vyulOp/v6mqqlJZWZk++OCDK46b7wpPfvb1na++vN94I18lz8TvS7FfOBf731zZu3evgoODVaZgldT4uR27JJXJKDjYqKSkRCdOnPBo7JdyIfa8r4JqHfveEwEKDq6u99jr83OXGt5n7+rnLtV/7DUBzVTWrUwfHGkm/+pL/1z21n5Tn/u85LnvSl+NXWoc3zd1FfuF87ATJ04oMDDQp2K/nIYWvy/HLjW+ff5yXIn/Uudi3o69pKREwcHB8jtxUKamdr8j/EuP1mv8xP6N+o69vlzq+OJNpaWlkiRjzBXb+ZmrtWjgjhw5ovbt22v79u1KSkqy5s+YMUO5ubnatWvXRevMnTtXTzzxRH2GCQAAAAAAAAAAfMwXX3yhDh06XHa5z9/J4o5HH31UaWlp1nRNTY2+/vprtW7dWn5+tav84WIlJSXq2LGjvvjiC4WHh3s7HKBBI18A15EvgGvIFcB15AvgGnIFcB35AriuoeWLMUalpaVq167dFdv5fJElMjJSAQEBF92ad+zYMcXExFxyHZvNJpvN5jQvIiKirkLE/wkPD28QyQH4AvIFcB35AriGXAFcR74AriFXANeRL4DrGlK+tGjR4qptajeAdAMQFBSkhIQEZWdnW/NqamqUnZ3tNHwYAAAAAAAAAACAJ/n8nSySlJaWpvHjx6tfv37q37+/nn/+eZ09e1YTJ070dmgAAAAAAAAAAKCRahRFljFjxuirr77S7NmzVVxcrD59+igrK0tt2rTxdmjQN8OzzZkz56Ih2gBcjHwBXEe+AK4hVwDXkS+Aa8gVwHXkC+A6X80XP2OM8XYQAAAAAAAAAAAAvsbnn8kCAAAAAAAAAADgDRRZAAAAAAAAAAAA3ECRBQAAAAAAAAAAwA0UWQAAAAAAAAAAANxAkQUedffddys2NlbBwcFq27atxo0bpyNHjji1+eSTTzR48GAFBwerY8eOeuaZZy7qZ/369erZs6eCg4N14403atOmTfW1CUC9OHTokCZNmqTOnTsrJCREN9xwg+bMmaPKykqnNn5+fhe9du7c6dQX+YLGzJVckTi2ABfMnz9fAwYMUGhoqCIiIi7Z5lLHljVr1ji1ycnJUd++fWWz2dS1a1dlZmbWffBAPXIlV+x2u0aOHKnQ0FBFR0dr+vTpOn/+vFMbcgVN0fXXX3/RcSQ9Pd2pjSvnZkBTsWTJEl1//fUKDg5WYmKiPvzwQ2+HBHjV3LlzLzqO9OzZ01p+7tw5Pfjgg2rdurXCwsI0atQoHTt2zIsRXx1FFnjU0KFDtW7dOhUVFekvf/mL9u/frx/+8IfW8pKSEt1+++3q1KmT8vLytHDhQs2dO1evvPKK1Wb79u36yU9+okmTJik/P1+pqalKTU3V7t27vbFJQJ3Ys2ePampqtGzZMn322Wd67rnntHTpUj322GMXtX3vvfd09OhR65WQkGAtI1/Q2LmSKxxbgP+qrKzU6NGj9ctf/vKK7VauXOl0bElNTbWWHTx4UCNHjtTQoUNVUFCghx9+WD//+c/1zjvv1HH0QP25Wq5UV1dr5MiRqqys1Pbt27Vq1SplZmZq9uzZVhtyBU3Zk08+6XQc+dWvfmUtc+XcDGgq1q5dq7S0NM2ZM0cfffSR4uPjlZKSouPHj3s7NMCrevfu7XQc2bp1q7XskUce0d/+9jetX79eubm5OnLkiH7wgx94MVoXGKAOvfXWW8bPz89UVlYaY4x56aWXTMuWLU1FRYXVZubMmaZHjx7W9I9+9CMzcuRIp34SExPN5MmT6ydowEueeeYZ07lzZ2v64MGDRpLJz8+/7DrkC5qib+cKxxbgYitXrjQtWrS45DJJ5o033rjsujNmzDC9e/d2mjdmzBiTkpLiwQiBhuFyubJp0ybj7+9viouLrXkvv/yyCQ8Pt4435Aqaqk6dOpnnnnvusstdOTcDmor+/fubBx980Jqurq427dq1MwsWLPBiVIB3zZkzx8THx19y2alTp0xgYKBZv369Na+wsNBIMjt27KinCK8dd7Kgznz99dd6/fXXNWDAAAUGBkqSduzYoVtvvVVBQUFWu5SUFBUVFenkyZNWm2HDhjn1lZKSoh07dtRf8IAXnD59Wq1atbpo/t13363o6GgNGjRIGzZscFpGvqAp+naucGwBrt2DDz6oyMhI9e/fXytWrJAxxlpGvgDf5MGNN96oNm3aWPNSUlJUUlKizz77zGpDrqCpSk9PV+vWrXXzzTdr4cKFTkPpuXJuBjQFlZWVysvLczpW+Pv7a9iwYRwr0OTt3btX7dq1U5cuXXTvvffKbrdLkvLy8lRVVeWUNz179lRsbGyDzhuKLPC4mTNnqnnz5mrdurXsdrveeusta1lxcbHTDxVJ1nRxcfEV21xYDjRG+/btU0ZGhiZPnmzNCwsL0+LFi7V+/Xpt3LhRgwYNUmpqqlOhhXxBU3OpXOHYAlybJ598UuvWrdPmzZs1atQoPfDAA8rIyLCWXy5fSkpKVF5eXt/hAl5Rm2MLuYLGburUqVqzZo22bNmiyZMn66mnntKMGTOs5a7kD9AUOBwOVVdX8zsE+JbExERlZmYqKytLL7/8sg4ePKjBgwertLRUxcXFCgoKuuiZeQ09byiy4KpmzZp1yQek/u9rz549Vvvp06crPz9f7777rgICAnTfffc5/XUk0Jhda75I0pdffqkRI0Zo9OjRuv/++635kZGRSktLU2Jiom655Ralp6dr7NixWrhwYX1vFuBxnswVoLFzJ1+u5PHHH9fAgQN18803a+bMmZoxYwbHFjQKns4VoCm5lvxJS0tTcnKybrrpJk2ZMkWLFy9WRkaGKioqvLwVAABfcMcdd2j06NG66aablJKSok2bNunUqVNat26dt0NzWzNvB4CGb9q0aZowYcIV23Tp0sX6f2RkpCIjI9W9e3fFxcWpY8eO2rlzp5KSkhQTE6Njx445rXthOiYmxvr3Um0uLAcasmvNlyNHjmjo0KEaMGCASw+CTExM1ObNm61p8gW+ypO5wrEFjd215su1SkxM1Lx581RRUSGbzXbZfAkPD1dISIjb7wPUNU/mSkxMjD788EOnea4eW8gV+KLa5E9iYqLOnz+vQ4cOqUePHi6dmwFNQWRkpAICAvgdAlxFRESEunfvrn379mn48OGqrKzUqVOnnO5maeh5Q5EFVxUVFaWoqCi31q2pqZEk6y9akpKS9Nvf/lZVVVXWc1o2b96sHj16qGXLllab7OxsPfzww1Y/mzdvVlJSUi22Aqgf15IvX375pYYOHaqEhAStXLlS/v5Xv7mwoKBAbdu2tabJF/gqT+YKxxY0drU5F3NFQUGBWrZsKZvNJumbfNm0aZNTG/IFvsCTuZKUlKT58+fr+PHjio6OlvRNHoSHh6tXr15WG3IFjUVt8qegoED+/v5WrrhybgY0BUFBQUpISFB2drZSU1MlfXOdLDs7Ww899JB3gwMakDNnzmj//v0aN26cEhISFBgYqOzsbI0aNUqSVFRUJLvd3rDPsQzgITt37jQZGRkmPz/fHDp0yGRnZ5sBAwaYG264wZw7d84YY8ypU6dMmzZtzLhx48zu3bvNmjVrTGhoqFm2bJnVz7Zt20yzZs3MokWLTGFhoZkzZ44JDAw0n376qbc2DfC4w4cPm65du5rbbrvNHD582Bw9etR6XZCZmWn++Mc/msLCQlNYWGjmz59v/P39zYoVK6w25AsaO1dyhWML8F//+c9/TH5+vnniiSdMWFiYyc/PN/n5+aa0tNQYY8yGDRvMH/7wB/Ppp5+avXv3mpdeesmEhoaa2bNnW30cOHDAhIaGmunTp5vCwkKzZMkSExAQYLKysry1WYDHXS1Xzp8/b77zne+Y22+/3RQUFJisrCwTFRVlHn30UasPcgVN0fbt281zzz1nCgoKzP79+83q1atNVFSUue+++6w2rpybAU3FmjVrjM1mM5mZmebf//63+cUvfmEiIiJMcXGxt0MDvGbatGkmJyfHHDx40Gzbts0MGzbMREZGmuPHjxtjjJkyZYqJjY0177//vvnXv/5lkpKSTFJSkpejvjKKLPCYTz75xAwdOtS0atXK2Gw2c/3115spU6aYw4cPO7X7+OOPzaBBg4zNZjPt27c36enpF/W1bt060717dxMUFGR69+5tNm7cWF+bAdSLlStXGkmXfF2QmZlp4uLiTGhoqAkPDzf9+/c369evv6gv8gWNmSu5YgzHFuCC8ePHXzJftmzZYowx5u233zZ9+vQxYWFhpnnz5iY+Pt4sXbrUVFdXO/WzZcsW06dPHxMUFGS6dOliVq5cWf8bA9Shq+WKMcYcOnTI3HHHHSYkJMRERkaaadOmmaqqKqd+yBU0NXl5eSYxMdG0aNHCBAcHm7i4OPPUU09Zf1h5gSvnZkBTkZGRYWJjY01QUJDp37+/2blzp7dDArxqzJgxpm3btiYoKMi0b9/ejBkzxuzbt89aXl5ebh544AHTsmVLExoaau655x6nP7RsiPyM4YnkAAAAAAAAAAAA1+rqDwAAAAAAAAAAAADARSiyAAAAAAAAAAAAuIEiCwAAAAAAAAAAgBsosgAAAAAAAAAAALiBIgsAAAAAAAAAAIAbKLIAAAAAAAAAAAC4gSILAAAAAAAAAACAGyiyAAAAAAAAAAAAuIEiCwAAAIBGx8/PT2+++aa3w6gzycnJevjhh70dBgAAANDkUWQBAAAAUGf8/Pyu+Jo7d+5l1z106JD8/PxUUFDg8bgmTJhgxRAYGKjOnTtrxowZOnfunMffCwAAAEDj1czbAQAAAABovI4ePWr9f+3atZo9e7aKioqseWFhYd4IS5I0YsQIrVy5UlVVVcrLy9P48ePl5+enp59+2msx/S9jjKqrq9WsGT/bAAAAgIaKO1kAAAAA1JmYmBjr1aJFC/n5+VnT0dHRevbZZ9WhQwfZbDb16dNHWVlZ1rqdO3eWJN18883y8/NTcnKyJOmf//ynhg8frsjISLVo0UJDhgzRRx99dM2x2Ww2xcTEqGPHjkpNTdWwYcO0efNma3lNTY0WLFigzp07KyQkRPHx8frzn/9sLe/Xr58WLVpkTaempiowMFBnzpyRJB0+fFh+fn7at2+fJOm1115Tv379dN111ykmJkY//elPdfz4cWv9nJwc+fn56e2331ZCQoJsNpu2bt2qs2fP6r777lNYWJjatm2rxYsXX/O2AgAAAKgbFFkAAAAAeMULL7ygxYsXa9GiRfrkk0+UkpKiu+++W3v37pUkffjhh5Kk9957T0ePHtVf//pXSVJpaanGjx+vrVu3aufOnerWrZvuvPNOlZaWuh3L7t27tX37dgUFBVnzFixYoFdffVVLly7VZ599pkceeURjx45Vbm6uJGnIkCHKycmR9M1dJx988IEiIiK0detWSVJubq7at2+vrl27SpKqqqo0b948ffzxx3rzzTd16NAhTZgw4aJYZs2apfT0dBUWFuqmm27S9OnTlZubq7feekvvvvuucnJy3CoqAQAAAPA87jsHAAAA4BWLFi3SzJkz9eMf/1iS9PTTT2vLli16/vnntWTJEkVFRUmSWrdurZiYGGu97373u079vPLKK4qIiFBubq6+973vufz+f//73xUWFqbz58+roqJC/v7++v3vfy9Jqqio0FNPPaX33ntPSUlJkqQuXbpo69atWrZsmYYMGaLk5GQtX75c1dXV2r17t4KCgjRmzBjl5ORoxIgRysnJ0ZAhQ6z3+9nPfmb9v0uXLnrxxRd1yy236MyZM07Dpj355JMaPny4JOnMmTNavny5Vq9erdtuu02StGrVKnXo0MHl7QQAAABQd7iTBQAAAEC9Kykp0ZEjRzRw4ECn+QMHDlRhYeEV1z127Jjuv/9+devWTS1atFB4eLjOnDkju91+TTEMHTpUBQUF2rVrl8aPH6+JEydq1KhRkqR9+/aprKxMw4cPV1hYmPV69dVXtX//fknS4MGDVVpaqvz8fOXm5lqFlwt3t+Tm5lpDnElSXl6e7rrrLsXGxuq6666zCjDfjrtfv37W//fv36/KykolJiZa81q1aqUePXpc07YCAAAAqBvcyQIAAADAp4wfP14nTpzQCy+8oE6dOslmsykpKUmVlZXX1E/z5s2tobxWrFih+Ph4LV++XJMmTbKeq7Jx40a1b9/eaT2bzSZJioiIUHx8vHJycrRjxw4NHz5ct956q8aMGaPPP/9ce/futQopZ8+eVUpKilJSUvT6668rKipKdrtdKSkpF8XdvHlztz4XAAAAAPWPO1kAAAAA1Lvw8HC1a9dO27Ztc5q/bds29erVS5Ks56NUV1df1Gbq1Km688471bt3b9lsNjkcjlrF4+/vr8cee0y/+93vVF5erl69eslms8lut6tr165Or44dO1rrDRkyRFu2bNE//vEPJScnq1WrVoqLi9P8+fPVtm1bde/eXZK0Z88enThxQunp6Ro8eLB69uzp9ND7y7nhhhsUGBioXbt2WfNOnjypzz//vFbbCwAAAMAzKLIAAAAA8Irp06fr6aef1tq1a1VUVKRZs2apoKBAv/71ryVJ0dHRCgkJUVZWlo4dO6bTp09Lkrp166bXXntNhYWF2rVrl+69916FhITUOp7Ro0crICBAS5Ys0XXXXaff/OY3euSRR7Rq1Srt379fH330kTIyMrRq1SprneTkZL3zzjtq1qyZevbsac17/fXXnZ7HEhsbq6CgIGVkZOjAgQPasGGD5s2bd9WYwsLCNGnSJE2fPl3vv/++du/erQkTJsjfn59yAAAAQEPAmTkAAAAAr5g6darS0tI0bdo03XjjjcrKytKGDRvUrVs3SVKzZs304osvatmyZWrXrp2+//3vS5KWL1+ukydPqm/fvho3bpymTp2q6OjoWsfTrFkzPfTQQ3rmmWd09uxZzZs3T48//rgWLFiguLg4jRgxQhs3blTnzp2tdQYPHqyamhqngkpycrKqq6udnscSFRWlzMxMrV+/Xr169VJ6eroWLVrkUlwLFy7U4MGDddddd2nYsGEaNGiQEhISar29AAAAAGrPzxhjvB0EAAAAAAAAAACAr+FOFgAAAAAAAAAAADdQZAEAAAAAAAAAAHADRRYAAAAAAAAAAAA3UGQBAAAAAAAAAABwA0UWAAAAAAAAAAAAN1BkAQAAAAAAAAAAcANFFgAAAAAAAAAAADdQZAEAAAAAAAAAAHADRRYAAAAAAAAAAAA3UGQBAAAAAAAAAABwA0UWAAAAAAAAAAAAN/x/svwkuD74bwMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure 2 (p. 222)\n",
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([tr_opt,tr_sym,tr_rl], bins=30,edgecolor='black', label=['Optimum', 'Symmetric','RL Discrete'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Total Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")\n",
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([tr_opt,tr_rl], bins=30,edgecolor='black', label=['Optimum','RL Discrete'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Total Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")\n",
    "fig=plt.figure(figsize=(20,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.hist([tr_opt,tr_sym], bins=30,edgecolor='black', label=['Optimum','Symmetric'])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Total Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Accumulated wealth histogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LUl_ON_bDS1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimo:\n",
      "47.79761695404737\n",
      "6.099978058681764\n",
      "7.83570309503321\n",
      "Simetrico:\n",
      "57.676984427753716\n",
      "11.86348257940186\n",
      "4.8617245435076715\n",
      "RL:\n",
      "49.527667125951055\n",
      "6.789843045021905\n",
      "7.294375848976826\n",
      "\n",
      "Optimum utility function value: \t-2.6283680458275698e-09\n",
      "Symmetric utility function value: \t-4.34167929750502e-06\n",
      "RL utility function value: \t\t-1.642129450494955e-09\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimo:\")\n",
    "print(np.mean(ws_opt))\n",
    "print(np.std(ws_opt))\n",
    "print(np.mean(ws_opt)/np.std(ws_opt))\n",
    "print(\"Simetrico:\")\n",
    "print(np.mean(ws_sym))\n",
    "print(np.std(ws_sym))\n",
    "print(np.mean(ws_sym)/np.std(ws_sym))\n",
    "print(\"RL:\")\n",
    "print(np.mean(ws_rl))\n",
    "print(np.std(ws_rl))\n",
    "print(np.mean(ws_rl)/np.std(ws_rl))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Optimum utility function value: \\t{}\".format(np.mean(-np.exp(-beta*ws_opt))))\n",
    "print(\"Symmetric utility function value: \\t{}\".format(np.mean(-np.exp(-beta*ws_sym))))\n",
    "print(\"RL utility function value: \\t\\t{}\".format(np.mean(-np.exp(-beta*ws_rl))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UJqDqpVIeGti"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimo:\n",
      "22.46050972128678\n",
      "3.4646472377108304\n",
      "6.482769580930536\n",
      "Simetrico:\n",
      "-7.172303914746957\n",
      "42.1491264960118\n",
      "-0.1701649479123988\n",
      "RL:\n",
      "25.613388701867564\n",
      "4.573544700540956\n",
      "5.600336364666563\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimo:\")\n",
    "print(np.mean(tr_opt))\n",
    "print(np.std(tr_opt))\n",
    "print(np.mean(tr_opt)/np.std(tr_opt))\n",
    "\n",
    "print(\"Simetrico:\")\n",
    "print(np.mean(tr_sym))\n",
    "print(np.std(tr_sym))\n",
    "print(np.mean(tr_sym)/np.std(tr_sym))\n",
    "\n",
    "print(\"RL:\")\n",
    "print(np.mean(tr_rl))\n",
    "print(np.std(tr_rl))\n",
    "print(np.mean(tr_rl)/np.std(tr_rl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sim_corregida.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
